{"cells":[{"cell_type":"markdown","metadata":{},"source":["# imports"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-21T21:37:17.590772Z","iopub.status.busy":"2024-03-21T21:37:17.590059Z","iopub.status.idle":"2024-03-21T21:37:20.815655Z","shell.execute_reply":"2024-03-21T21:37:20.814795Z","shell.execute_reply.started":"2024-03-21T21:37:17.590738Z"},"trusted":true},"outputs":[],"source":["from datetime import datetime\n","import einops\n","import wandb\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt \n","from torch.utils.data import Dataset, DataLoader, random_split, Subset\n","import torch as t\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from functools import lru_cache\n","\n","device = 'cuda' if t.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["# utils"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.817280Z","iopub.status.busy":"2024-03-21T21:37:20.816807Z","iopub.status.idle":"2024-03-21T21:37:20.821939Z","shell.execute_reply":"2024-03-21T21:37:20.820711Z","shell.execute_reply.started":"2024-03-21T21:37:20.817254Z"},"trusted":true},"outputs":[],"source":["import gc \n","def GC():\n","    gc.collect()\n","    t.cuda.empty_cache()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["@t.no_grad()\n","def eval(model, x, y, do_eval=True):\n","    assert not x.isnan().any()\n","    assert not y.isnan().any()\n","    if do_eval: model.eval()\n","    else: model.train()\n","    logs = model(x.to(device)).log_softmax(-1)\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    loss = kl_loss(logs, y.to(device))\n","    model.train()\n","    return loss"]},{"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.824665Z","iopub.status.busy":"2024-03-21T21:37:20.824388Z","iopub.status.idle":"2024-03-21T21:37:20.832864Z","shell.execute_reply":"2024-03-21T21:37:20.831925Z","shell.execute_reply.started":"2024-03-21T21:37:20.824642Z"},"trusted":true},"outputs":[],"source":["batch_size = 45\n","prefetch_factor = 10\n","num_workers = 3"]},{"cell_type":"markdown","metadata":{},"source":["# data"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.834301Z","iopub.status.busy":"2024-03-21T21:37:20.834002Z","iopub.status.idle":"2024-03-21T21:37:20.842316Z","shell.execute_reply":"2024-03-21T21:37:20.841423Z","shell.execute_reply.started":"2024-03-21T21:37:20.834277Z"},"trusted":true},"outputs":[],"source":["test_path = './hms-harmful-brain-activity-classification/test_eegs/'\n","train_path = './hms-harmful-brain-activity-classification/train_eegs/'\n","train_spec_path = './hms-harmful-brain-activity-classification/train_spectrograms/'\n","BASE_PATH = './hms-harmful-brain-activity-classification/'\n","PRE_PROCESSED_PATH = './preprocessed/'\n","\n","FEATS_FOR_REAL = ['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n","#                   0      1     2     3     4     5     6     7     8     9    10     11    12    13    14    15    16    17    18    19\n","# group by semantic groups LP, LL, RP, RR https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Jan-2024/montage.png\n","# GROUPS = [\n","#     ['Fp1', 'F3', 'C3', 'P3', 'O1'],\n","#     ['Fp1', 'F7', 'T3', 'T5', 'O1'],\n","#     ['Fp2', 'F4', 'C4', 'P4', 'O2'],\n","#     ['Fp2', 'F8', 'T4', 'T6', 'O2'],\n","# ]\n","GROUPS_IDS = [\n","    [0, 1, 2, 3, 7],\n","    [0, 4, 5, 6, 7],\n","    [11, 12, 13, 14, 18],\n","    [11, 15, 16, 17, 18],\n","    # [8, 9, 10, 19] # TODO: try with leftovers?\n","]\n","# TODO: add frequency domain with fourier's transform\n","# TODO: add spectrogram to process with conv2d\n","# TODO: merge several models together\n","\n","TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote','other_vote']"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.864280Z","iopub.status.busy":"2024-03-21T21:37:20.863567Z","iopub.status.idle":"2024-03-21T21:37:21.129666Z","shell.execute_reply":"2024-03-21T21:37:21.128636Z","shell.execute_reply.started":"2024-03-21T21:37:20.864246Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(f'{BASE_PATH}/train.csv')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:21.131192Z","iopub.status.busy":"2024-03-21T21:37:21.130854Z","iopub.status.idle":"2024-03-21T21:37:21.139945Z","shell.execute_reply":"2024-03-21T21:37:21.138915Z","shell.execute_reply.started":"2024-03-21T21:37:21.131165Z"},"trusted":true},"outputs":[],"source":["class Dataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","        self.dataframe = train_df\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    # @lru_cache(maxsize=None)\n","    def __getitem__(self, idx): # preprocessed version\n","        row = self.dataframe.iloc[idx]\n","        eeg_id = row['eeg_id']\n","        eeg_sub_id = row['eeg_sub_id']\n","        eeg_path = f'{PRE_PROCESSED_PATH}/{eeg_id}_{eeg_sub_id}.pt'\n","        eeg = t.load(eeg_path)\n","        labels = row[TARGETS].values.astype(np.float64)\n","        labels = labels/np.sum(labels)\n","        labels_out = t.tensor(labels, dtype=t.float64)\n","        \n","        # assert not samples.isnan().any()\n","        # assert not labels_out.isnan().any()\n","        return eeg, labels_out"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["(102169, 4631)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["dataset = Dataset()\n","ids = train_df['eeg_id'].unique()\n","np.random.shuffle(ids)\n","split = int(len(ids) * 0.95)\n","\n","train_ids = ids[:split]\n","test_ids = ids[split:]\n","\n","now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","t.save(t.tensor(train_ids), f'./splits/{now}_train_ids.pt')\n","t.save(t.tensor(train_ids), f'./splits/{now}_test_ids.pt')\n","\n","train_indices = train_df[train_df['eeg_id'].isin(train_ids)].index.tolist()\n","test_indices = train_df[train_df['eeg_id'].isin(test_ids)].index.tolist()\n","\n","train_dataset = Subset(dataset, train_indices)\n","test_dataset = Subset(dataset, test_indices)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","\n","len(train_dataset), len(test_dataset)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:21.141543Z","iopub.status.busy":"2024-03-21T21:37:21.141187Z","iopub.status.idle":"2024-03-21T21:37:21.159501Z","shell.execute_reply":"2024-03-21T21:37:21.158788Z","shell.execute_reply.started":"2024-03-21T21:37:21.141517Z"},"trusted":true},"outputs":[],"source":["# dataset = Dataset()\n","# train_size = int(len(dataset) * 0.95)\n","# test_size = len(dataset) - train_size\n","# train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","# # TODO: check for overlap because train and test seem to be too correlated compared to the leaderboard data\n","\n","# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers) #, prefetch_factor=prefetch_factor, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# model ðŸ‘¯â€â™€ï¸"]},{"cell_type":"markdown","metadata":{},"source":["## conv1d + GRU"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:21.178778Z","iopub.status.busy":"2024-03-21T21:37:21.178518Z","iopub.status.idle":"2024-03-21T21:37:22.707099Z","shell.execute_reply":"2024-03-21T21:37:22.705508Z","shell.execute_reply.started":"2024-03-21T21:37:21.178755Z"},"trusted":true},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, d_in, d_out, kernel_size, drop):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv1d(d_in, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0), # reduce sequence size by 2\n","        )\n","    def forward(self, x):\n","        # TODO: add skip for training speed\n","        return self.model(x)\n","        \n","class Model(nn.Module):\n","    def __init__(self, in_channels=20, gru_hidden_size=128, drop=0.2):\n","        super().__init__()\n","        self.pre_out = in_channels * 4\n","        self.gru_hidden_size = gru_hidden_size\n","        \n","        self.pre_process = nn.Sequential(\n","            nn.BatchNorm1d(in_channels, momentum=None),\n","            # use conv1d as a denoiser\n","            # block 1\n","            ConvBlock(in_channels, in_channels * 2, kernel_size=3, drop=drop),\n","            nn.BatchNorm1d(in_channels * 2, momentum=None),\n","            \n","            # block 2\n","            ConvBlock(in_channels * 2, in_channels * 4, kernel_size=5, drop=drop),\n","            nn.BatchNorm1d(self.pre_out, momentum=None),\n","\n","            # block 3\n","            ConvBlock(in_channels * 4, in_channels * 4, kernel_size=7, drop=drop),\n","            nn.BatchNorm1d(self.pre_out, momentum=None),\n","        )\n","        \n","        # TODO: add a learnable first state for GRU or check what is the default\n","        self.gru = nn.GRU(self.pre_out, self.gru_hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n","\n","        self.head = nn.Sequential(\n","            nn.Linear(self.gru_hidden_size * 2, self.gru_hidden_size * 4),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size * 4, 6)\n","        )\n","\n","    def forward(self, x: ('batch', 'seq', 'channel')):\n","        # pre_process: (batch, channel, seq) â†’ (batch / 4, channel * 4, seq)\n","        x = x.permute((0, 2, 1))\n","        x = self.pre_process(x)\n","        x = x.permute((0, 2, 1))\n","\n","        # GRU: (batch, seq, input_size), [(2 * num_layers, batch, hidden_size)] â†’ (batch, seq, 2 * hidden_size)\n","        x, _ = self.gru(x)\n","        x = x[:, -1, :]\n","\n","        # head: (batch, 2 * hidden_size) â†’ (batch, 6)\n","        x = self.head(x)\n","\n","        # out: â†’ (batch, 6)\n","        return x\n","\n","def scope():\n","    m = Model().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["## transformer"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, d_chan=20, d_model=256, d_clump=4):\n","        super().__init__()\n","        self.d_clump = d_clump\n","\n","        self.start = nn.Parameter(t.randn(1, 1, d_model))\n","        self.bn = nn.BatchNorm1d(d_chan)\n","        self.emb = nn.Linear(d_chan * d_clump, d_model)\n","        self.llm = nn.Transformer(d_model=d_model, nhead=8, num_encoder_layers=3, num_decoder_layers=0, dim_feedforward=d_model * 2, batch_first=True)\n","        self.head = nn.Sequential(\n","            nn.Linear(d_model, d_model // 2),\n","            nn.ReLU(),\n","            nn.Linear(d_model // 2, 6)\n","        )\n","\n","    def forward(self, x):\n","        x = self.bn(x.permute((0, 2, 1))).permute((0, 2, 1))\n","        x = einops.rearrange(x, 'batch (seq clump) channels -> batch seq (clump channels)', clump=self.d_clump)\n","        x = self.emb(x)\n","        # add a fake start token\n","        x = t.cat([self.start.repeat(x.shape[0], 1, 1), x], dim=1)\n","        x = self.llm.encoder(x)[:, 0]\n","        return self.head(x)\n","\n","def scope():\n","    val, label = next(train_dataloader.__iter__())\n","    model = Transformer().to(device)\n","    output = model(val.to(device))\n","\n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["## separated GRU"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, d_in, d_out, kernel_size, drop):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv1d(d_in, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0), # reduce sequence size by 2\n","        )\n","    def forward(self, x):\n","        # TODO: add skip for training speed\n","        return self.model(x)\n","        \n","class SeparatedGRU(nn.Module):\n","    def __init__(self, in_channels=5, gru_hidden_size=128, drop=0.1):\n","        super().__init__()\n","        self.d_split = len(GROUPS_IDS)\n","        self.pre_out = in_channels * 4\n","        self.gru_hidden_size = gru_hidden_size\n","        \n","        self.pre_process = nn.Sequential(\n","            nn.BatchNorm1d(in_channels, momentum=None),\n","            # use conv1d as a denoiser\n","            # block 1\n","            ConvBlock(in_channels, in_channels * 2, kernel_size=3, drop=drop),\n","            # nn.BatchNorm1d(in_channels * 2, momentum=None),\n","            \n","            # block 2\n","            ConvBlock(in_channels * 2, in_channels * 4, kernel_size=5, drop=drop),\n","            # nn.BatchNorm1d(self.pre_out, momentum=None),\n","\n","            # block 3\n","            ConvBlock(in_channels * 4, in_channels * 4, kernel_size=7, drop=drop),\n","            nn.BatchNorm1d(in_channels * 4, momentum=None), # re-enable one more to force training ?\n","        )\n","        \n","        # TODO: add a learnable first state for GRU or check what is the default\n","        self.gru = nn.GRU(self.pre_out, self.gru_hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n","\n","        self.post_gru = nn.Sequential(\n","            nn.Linear(self.gru_hidden_size * 2, self.gru_hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(self.gru_hidden_size, self.gru_hidden_size),\n","        )\n","\n","        self.head = nn.Sequential(\n","            nn.Linear(self.gru_hidden_size * self.d_split, self.gru_hidden_size * 2),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size * 2, 6)\n","        )\n","\n","    def forward(self, x: ('batch', 'seq', 'channel')):\n","        # separate the input into 4 splits (LP, LL, RP, RR)\n","        splits = [x[:, :, group] for group in GROUPS_IDS]\n","        # fold it into batch so we can run in parallel\n","        x = einops.rearrange(t.stack(splits, dim=0), 'group batch seq channel -> (group batch) seq channel')\n","\n","        # pre_process: (batch, channel, seq) â†’ (batch / 4, channel * 4, seq)\n","        x = x.permute((0, 2, 1))\n","        x = self.pre_process(x)\n","        x = x.permute((0, 2, 1))\n","\n","        # GRU: (batch, seq, input_size), [(2 * num_layers, batch, hidden_size)] â†’ (batch, seq, 2 * hidden_size)\n","        x, _ = self.gru(x)\n","        x = x[:, -1, :]\n","\n","        # MLP post GRU\n","        x = self.post_gru(x)\n","\n","        # unfold the splits\n","        x = einops.rearrange(x, '(group batch) hidden -> batch (hidden group)', group=self.d_split)\n","\n","        # head: (batch, 2 * hidden_size) â†’ (batch, 6)\n","        x = self.head(x)\n","\n","        # out: â†’ (batch, 6)\n","        return x\n","\n","def scope():\n","    m = SeparatedGRU().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["# train"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:22.709455Z","iopub.status.busy":"2024-03-21T21:37:22.709032Z","iopub.status.idle":"2024-03-21T21:37:24.020300Z","shell.execute_reply":"2024-03-21T21:37:24.019345Z","shell.execute_reply.started":"2024-03-21T21:37:22.709406Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model has 311828 params\n"]}],"source":["GC()\n","# model = Model().to(device)\n","# model = Transformer().to(device)\n","model = SeparatedGRU().to(device)\n","# TODO: try cranking the weight decay\n","# TODO: try using a scheduler\n","opt = t.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n","print(f'model has {sum(p.numel() for p in model.parameters())} params')"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:24.022207Z","iopub.status.busy":"2024-03-21T21:37:24.021641Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeluche\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240325_033146-1gg812p4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/1gg812p4' target=\"_blank\">colorful-snowflake-42</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/1gg812p4' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/1gg812p4</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06b98a9105d742439dbbecf73b9cf3e4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fea177690ac42bc82c4bd24fe96eea8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bd2db183c854778a629c4fa94f21df7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28832f3939554cd4a76159db1fafc27d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb3427b0d2bb4d08bd80a153a4f8d807","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5709ae12a93e434e886188d7b16544e7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4203c80c38e44fda6f670b663347528","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e1b076d3f864fa48dd8598ff48a7c83","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a4bafea52f94192a82f75b784e9c757","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be9f7125a351467e964a305e2c75519c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"559e3d7809ff486aadbddb3ebd7f1f61","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14d15902c20e4439b6ff3a3454ad2bb0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98940c45b0e94ebc8de3777093e0d078","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b09697aa19744d4d973cd06026596c6f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d1905de3e1e41a6ac6a7b4084d425e2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43639bcf679b4ca695a2340f00a6dfe5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21ce2478ccdf49ac9906b436124d5eed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5072528743a646a092841e943396bb15","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e763ae7ac401415f9e3a6c2a3925ba29","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5c1fb0440cf46b8bce2997cfcc49fce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"314709c755fe4946ba271507a0af1539","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfcfeb18c1444e0583f8721e14b9e9e8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c499cb30b68a4b2cacf2619c103519bd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d03b268bc2f043458be09bccd9093d47","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb6547b406294681997367d3b04c65e5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59acf95331b449ebaa8bda1cb59a8c91","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aee48923e8884c18b9be0f25e385698f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a71af8ed6b97483ba6ee87859820d739","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f207bb34a6ab48859dbc41d58b717be9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3aad601103540ebabfb64cfa28cc07d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a6b2acd2b60457ea30f76a184a09efa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab14438545b94041b949b19e15f988ff","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcfd86beb0d7414f8b91a5b516f3c071","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e5f477d5e0247e68ac668d4f88cf546","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f400327099244a3290e5edab7a9b11f0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b9ef7695a994f8fb84f7d8ecb751ffc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5da917ba5fa47a1a1a247f9bf6255ae","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0731b45102e4c078245aad3689d0092","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9872eab034bf4d058f49a654c39fb2ce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"533c87ad8437488192e5c9532b74cdef","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4eb9a92b120e4db8b80466ea8cbe991f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2de09d2230564b409707ce461f8a0952","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50a13954ea154455a6460f392c97e748","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72478d00403e415a91a1cc2c3d7f3f3b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2943918174544bf7b4cc21cb9e1db135","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db72db5041f54d9c837c39ff3330ff8e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66efec1279ab40deb6ae4a95f8493fd4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72ea3cd4fad5403ea1cb0be509c0d00a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a30c287dea28450487b968b56f8a9359","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"567eaeeb3bfe49d3a8f647bae5c0fa44","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1855870b11ff4825acec0626cae31199","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab272d8a0475474db85e8b65943032a2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67757d9afcd44814915aa1499e0c897d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6349a9c98f994482ab5f20c9d19df1d2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec41c90138494aecbffb652b42f44ae8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5022da37f9043a4a773a72859f858bb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1068628611946e1aebb9c599ea52148","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ac11da8f2e44827a99e91cf2fc94113","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1eb4e411474443bd812d358584f9c2b5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2176b301f7d4ac3be6f3677413bfe29","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f05a4cd2ac55405b8132d64770df958e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ace5d6247e33451081130a238631da9c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9cedbf92d60432ba4bbb5e00db5d117","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34034d4835594a3abce80f4e403cc70f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcec5b161db344b18c8bab44efc1df3b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"131b550e9fe0401aa11a4ad8473008b8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cb95de111a204b3aa8b142d0eb03a9f7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff7cf0ef24f847eda5922229a2400105","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce64a69bff0a4131a2a12f754bd9c895","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81bfdfa2e1694904aa988eee1213567a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2271 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def train(model, opt, wnb=True, do_eval=True):\n","    model.train()\n","    validation_test, validation_test_label = next(test_dataloader.__iter__())\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb: wandb.init(project='kaggle-eeg-rc')\n","    for epoch in range(1000):\n","        replay_buffer, maxi = [], 4\n","        tq = tqdm(train_dataloader)\n","        for x_train, y_train in tq:\n","            replay_buffer.append((x_train, y_train))\n","            replay_buffer = replay_buffer[-maxi:]\n","            for x_train, y_train in replay_buffer: # burn more GPU otherwise we bottleneck on disk IO\n","            # for k in range(3): # the data reading is too slow, so force the GPU to spin\n","                logs = model(x_train.to(device)).log_softmax(-1)\n","                kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","                loss = kl_loss(logs, y_train.to(device))\n","                opt.zero_grad()\n","                loss.backward()\n","                opt.step()\n","                tq.set_description(f'loss = {loss:.4f}')\n","                if wnb: wandb.log({'loss': loss.item()})\n","        if wnb and do_eval:\n","            wandb.log({'validation_test-eval':   eval(model, validation_test, validation_test_label, do_eval=True)})\n","            wandb.log({'validation_test-train':  eval(model, validation_test, validation_test_label, do_eval=False)})\n","            wandb.log({'validation_train-eval':  eval(model, validation_train, validation_train_label, do_eval=True)})\n","            wandb.log({'validation_train-train': eval(model, validation_train, validation_train_label, do_eval=False)})\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        t.save(model.state_dict(), f'weights/gru-4-splits_{now}.pt')\n","    if wnb: wandb.finish()\n","\n","train(model, opt, wnb=True)"]},{"cell_type":"markdown","metadata":{},"source":["# save / load"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# t.save(model.state_dict(),'model-weights4.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["# model = SeparatedGRU().to(device)\n","# model.load_state_dict(t.load('weights/gru-4-splits_2024-03-24_15h03.pt', map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train.eval(): 0.18152604880545462\n","val.eval():  0.1698637661260274\n","--\n","train.train(): 0.18602605100710143\n","val.train():  0.24629601047938124\n"]}],"source":["x_train, y_train = next(train_dataloader.__iter__())\n","x_val, y_val = next(test_dataloader.__iter__())\n","\n","print(f'train.eval(): {eval(model, x_train, y_train, do_eval=True)}')\n","print(f'val.eval():  {eval(model, x_val, y_val, do_eval=True)}')\n","print('--')\n","print(f'train.train(): {eval(model, x_train, y_train, do_eval=False)}')\n","print(f'val.train():  {eval(model, x_val, y_val, do_eval=False)}')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4638387,"sourceId":7898450,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
