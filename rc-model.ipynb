{"cells":[{"cell_type":"markdown","metadata":{},"source":["# imports"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-21T21:37:17.590772Z","iopub.status.busy":"2024-03-21T21:37:17.590059Z","iopub.status.idle":"2024-03-21T21:37:20.815655Z","shell.execute_reply":"2024-03-21T21:37:20.814795Z","shell.execute_reply.started":"2024-03-21T21:37:17.590738Z"},"trusted":true},"outputs":[],"source":["from datetime import datetime\n","import einops\n","import wandb\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt \n","from torch.utils.data import Dataset, DataLoader, random_split, Subset\n","import torch as t\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from functools import lru_cache\n","\n","device = 'cuda' if t.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["# utils"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.817280Z","iopub.status.busy":"2024-03-21T21:37:20.816807Z","iopub.status.idle":"2024-03-21T21:37:20.821939Z","shell.execute_reply":"2024-03-21T21:37:20.820711Z","shell.execute_reply.started":"2024-03-21T21:37:20.817254Z"},"trusted":true},"outputs":[],"source":["import gc \n","def GC():\n","    gc.collect()\n","    t.cuda.empty_cache()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# validation / inference loss\n","@t.no_grad()\n","def eval(model, x, y, do_eval=True):\n","    assert not x.isnan().any()\n","    assert not y.isnan().any()\n","    if do_eval: model.eval()\n","    else: model.train()\n","    logs = model(x.to(device)).log_softmax(-1)\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    loss = kl_loss(logs, y.to(device))\n","    model.train()\n","    return loss"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["@t.no_grad()\n","def augment_data(data, alpha=0.3):\n","    # was alpha=0.01 try 0.3\n","    # data ‚Üí ('batch', 'seq', 'channel')\n","    data = data.to(device)\n","    std = data.std(dim=1, keepdim=True)\n","    noise = t.randn_like(data, device=device) * std * alpha\n","    return data + noise\n","\n","def augment_if(data, iter):\n","    if iter == 0: return data\n","    return augment_data(data)"]},{"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.824665Z","iopub.status.busy":"2024-03-21T21:37:20.824388Z","iopub.status.idle":"2024-03-21T21:37:20.832864Z","shell.execute_reply":"2024-03-21T21:37:20.831925Z","shell.execute_reply.started":"2024-03-21T21:37:20.824642Z"},"trusted":true},"outputs":[],"source":["batch_size = 45\n","prefetch_factor = 10\n","num_workers = 3"]},{"cell_type":"markdown","metadata":{},"source":["# data"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.834301Z","iopub.status.busy":"2024-03-21T21:37:20.834002Z","iopub.status.idle":"2024-03-21T21:37:20.842316Z","shell.execute_reply":"2024-03-21T21:37:20.841423Z","shell.execute_reply.started":"2024-03-21T21:37:20.834277Z"},"trusted":true},"outputs":[],"source":["test_path = './hms-harmful-brain-activity-classification/test_eegs/'\n","train_path = './hms-harmful-brain-activity-classification/train_eegs/'\n","train_spec_path = './hms-harmful-brain-activity-classification/train_spectrograms/'\n","BASE_PATH = './hms-harmful-brain-activity-classification/'\n","# PRE_PROCESSED_PATH = './preprocessed/'\n","# PRE_PROCESSED_PATH = './eeg-filtered/'\n","# PRE_PROCESSED_PATH = './eeg-logged/'\n","PRE_PROCESSED_PATH = './eeg-robust-filter/'\n","\n","FEATS_FOR_REAL = ['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n","#                   0      1     2     3     4     5     6     7     8     9    10     11    12    13    14    15    16    17    18    19\n","# group by semantic groups LP, LL, RP, RR https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Jan-2024/montage.png\n","# GROUPS = [\n","#     ['Fp1', 'F3', 'C3', 'P3', 'O1'],\n","#     ['Fp1', 'F7', 'T3', 'T5', 'O1'],\n","#     ['Fp2', 'F4', 'C4', 'P4', 'O2'],\n","#     ['Fp2', 'F8', 'T4', 'T6', 'O2'],\n","# ]\n","GROUPS_IDS = [\n","    [0, 1, 2, 3, 7],\n","    [0, 4, 5, 6, 7],\n","    [11, 12, 13, 14, 18],\n","    [11, 15, 16, 17, 18],\n","    # [8, 9, 10, 19] # TODO: try with leftovers?\n","]\n","# LEFTOVERS = [8, 9, 10]\n","# EKG = [19]\n","# TODO: add frequency domain with fourier's transform\n","# TODO: add spectrogram to process with conv2d\n","# TODO: merge several models together\n","\n","TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote','other_vote']"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.864280Z","iopub.status.busy":"2024-03-21T21:37:20.863567Z","iopub.status.idle":"2024-03-21T21:37:21.129666Z","shell.execute_reply":"2024-03-21T21:37:21.128636Z","shell.execute_reply.started":"2024-03-21T21:37:20.864246Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(f'{BASE_PATH}/train.csv')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:21.131192Z","iopub.status.busy":"2024-03-21T21:37:21.130854Z","iopub.status.idle":"2024-03-21T21:37:21.139945Z","shell.execute_reply":"2024-03-21T21:37:21.138915Z","shell.execute_reply.started":"2024-03-21T21:37:21.131165Z"},"trusted":true},"outputs":[],"source":["class Dataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","        self.dataframe = train_df\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    # @lru_cache(maxsize=None)\n","    def __getitem__(self, idx): # preprocessed version\n","        row = self.dataframe.iloc[idx]\n","        eeg_id = row['eeg_id']\n","        eeg_sub_id = row['eeg_sub_id']\n","        eeg_path = f'{PRE_PROCESSED_PATH}/{eeg_id}_{eeg_sub_id}.pt'\n","        eeg = t.load(eeg_path)\n","        labels = row[TARGETS].values.astype(np.float64)\n","        labels = labels/np.sum(labels)\n","        labels_out = t.tensor(labels, dtype=t.float64)\n","        \n","        # assert not samples.isnan().any()\n","        # assert not labels_out.isnan().any()\n","        return eeg, labels_out"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["(102085, 4715)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["dataset = Dataset()\n","ids = train_df['eeg_id'].unique()\n","np.random.shuffle(ids)\n","split = int(len(ids) * 0.95)\n","\n","train_ids = ids[:split]\n","test_ids = ids[split:]\n","\n","now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","t.save(t.tensor(train_ids), f'./splits/{now}_train_ids.pt')\n","t.save(t.tensor(train_ids), f'./splits/{now}_test_ids.pt')\n","\n","train_indices = train_df[train_df['eeg_id'].isin(train_ids)].index.tolist()\n","test_indices = train_df[train_df['eeg_id'].isin(test_ids)].index.tolist()\n","\n","train_dataset = Subset(dataset, train_indices)\n","test_dataset = Subset(dataset, test_indices)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","\n","len(train_dataset), len(test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# model üëØ‚Äç‚ôÄÔ∏è"]},{"cell_type":"markdown","metadata":{},"source":["## conv1d + GRU"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:21.178778Z","iopub.status.busy":"2024-03-21T21:37:21.178518Z","iopub.status.idle":"2024-03-21T21:37:22.707099Z","shell.execute_reply":"2024-03-21T21:37:22.705508Z","shell.execute_reply.started":"2024-03-21T21:37:21.178755Z"},"trusted":true},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, d_in, d_out, kernel_size, drop):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv1d(d_in, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0), # reduce sequence size by 2\n","        )\n","    def forward(self, x):\n","        # TODO: add skip for training speed\n","        return self.model(x)\n","        \n","class Model(nn.Module):\n","    def __init__(self, in_channels=20, gru_hidden_size=128, drop=0.2):\n","        super().__init__()\n","        self.pre_out = in_channels * 4\n","        self.gru_hidden_size = gru_hidden_size\n","        \n","        self.pre_process = nn.Sequential(\n","            nn.BatchNorm1d(in_channels, momentum=None),\n","            # use conv1d as a denoiser\n","            # block 1\n","            ConvBlock(in_channels, in_channels * 2, kernel_size=3, drop=drop),\n","            nn.BatchNorm1d(in_channels * 2, momentum=None),\n","            \n","            # block 2\n","            ConvBlock(in_channels * 2, in_channels * 4, kernel_size=5, drop=drop),\n","            nn.BatchNorm1d(self.pre_out, momentum=None),\n","\n","            # block 3\n","            ConvBlock(in_channels * 4, in_channels * 4, kernel_size=7, drop=drop),\n","            nn.BatchNorm1d(self.pre_out, momentum=None),\n","        )\n","        \n","        # TODO: add a learnable first state for GRU or check what is the default\n","        self.gru = nn.GRU(self.pre_out, self.gru_hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n","\n","        self.head = nn.Sequential(\n","            nn.Linear(self.gru_hidden_size * 2, self.gru_hidden_size * 4),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size * 4, 6)\n","        )\n","\n","    def forward(self, x: ('batch', 'seq', 'channel')):\n","        # pre_process: (batch, channel, seq) ‚Üí (batch / 4, channel * 4, seq)\n","        x = x.permute((0, 2, 1))\n","        x = self.pre_process(x)\n","        x = x.permute((0, 2, 1))\n","\n","        # GRU: (batch, seq, input_size), [(2 * num_layers, batch, hidden_size)] ‚Üí (batch, seq, 2 * hidden_size)\n","        x, _ = self.gru(x)\n","        x = x[:, -1, :]\n","\n","        # head: (batch, 2 * hidden_size) ‚Üí (batch, 6)\n","        x = self.head(x)\n","\n","        # out: ‚Üí (batch, 6)\n","        return x\n","\n","def scope():\n","    m = Model().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["## transformer"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, d_chan=20, d_model=256, d_clump=4):\n","        super().__init__()\n","        self.d_clump = d_clump\n","\n","        self.start = nn.Parameter(t.randn(1, 1, d_model))\n","        self.bn = nn.BatchNorm1d(d_chan)\n","        self.emb = nn.Linear(d_chan * d_clump, d_model)\n","        self.llm = nn.Transformer(d_model=d_model, nhead=8, num_encoder_layers=3, num_decoder_layers=0, dim_feedforward=d_model * 2, batch_first=True)\n","        self.head = nn.Sequential(\n","            nn.Linear(d_model, d_model // 2),\n","            nn.ReLU(),\n","            nn.Linear(d_model // 2, 6)\n","        )\n","\n","    def forward(self, x):\n","        x = self.bn(x.permute((0, 2, 1))).permute((0, 2, 1))\n","        x = einops.rearrange(x, 'batch (seq clump) channels -> batch seq (clump channels)', clump=self.d_clump)\n","        x = self.emb(x)\n","        # add a fake start token\n","        x = t.cat([self.start.repeat(x.shape[0], 1, 1), x], dim=1)\n","        x = self.llm.encoder(x)[:, 0]\n","        return self.head(x)\n","\n","def scope():\n","    val, label = next(train_dataloader.__iter__())\n","    model = Transformer().to(device)\n","    output = model(val.to(device))\n","\n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["## separated GRU"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, d_in, d_out, kernel_size, drop):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv1d(d_in, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0), # reduce sequence size by 2\n","        )\n","    def forward(self, x):\n","        # TODO: add skip for training speed\n","        return self.model(x)\n","        \n","class SeparatedGRU_old(nn.Module):\n","    def __init__(self, in_channels=5, gru_hidden_size=128, drop=0.2):\n","        super().__init__()\n","        self.d_split = len(GROUPS_IDS)\n","        self.pre_out = in_channels * 4\n","        self.gru_hidden_size = gru_hidden_size\n","        \n","        self.pre_process = nn.Sequential(\n","            # nn.LayerNorm(normalized_shape=[in_channels, 10000]),\n","            nn.BatchNorm1d(in_channels, momentum=None),\n","            # use conv1d as a denoiser\n","            # block 1\n","            ConvBlock(in_channels, in_channels * 2, kernel_size=3, drop=drop),\n","            # nn.BatchNorm1d(in_channels * 2, momentum=None),\n","            \n","            # block 2\n","            ConvBlock(in_channels * 2, in_channels * 4, kernel_size=5, drop=drop),\n","            # nn.BatchNorm1d(in_channels * 4, momentum=None),\n","\n","            # block 3\n","            ConvBlock(in_channels * 4, in_channels * 4, kernel_size=7, drop=drop),\n","            # nn.BatchNorm1d(in_channels * 4, momentum=None), # re-enable one more to force training ?\n","        )\n","        \n","        # TODO: add a learnable first state for GRU or check what is the default\n","        self.gru = nn.GRU(self.pre_out, self.gru_hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n","\n","        self.post_gru = nn.Sequential(\n","            # nn.BatchNorm1d(self.gru_hidden_size * 2, momentum=None),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size * 2, self.gru_hidden_size),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size, self.gru_hidden_size),\n","        )\n","\n","        self.head = nn.Sequential(\n","            # nn.BatchNorm1d(self.gru_hidden_size * self.d_split, momentum=None),\n","            nn.Linear(self.gru_hidden_size * self.d_split, self.gru_hidden_size * 2),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size * 2, 6)\n","        )\n","\n","    def forward(self, x: ('batch', 'seq', 'channel')):\n","        # separate the input into 4 splits (LP, LL, RP, RR)\n","        splits = [x[:, :, group] for group in GROUPS_IDS]\n","        # fold it into batch so we can run in parallel\n","        x = einops.rearrange(t.stack(splits, dim=0), 'group batch seq channel -> (group batch) seq channel')\n","\n","        # pre_process: (batch, channel, seq) ‚Üí (batch / 4, channel * 4, seq)\n","        x = x.permute((0, 2, 1))\n","        x = self.pre_process(x)\n","        x = x.permute((0, 2, 1))\n","\n","        # GRU: (batch, seq, input_size), [(2 * num_layers, batch, hidden_size)] ‚Üí (batch, seq, 2 * hidden_size)\n","        x, _ = self.gru(x)\n","        x = x[:, -1, :]\n","\n","        # MLP post GRU\n","        x = self.post_gru(x)\n","\n","        # unfold the splits\n","        x = einops.rearrange(x, '(group batch) hidden -> batch (hidden group)', group=self.d_split)\n","\n","        # head: (batch, 2 * hidden_size) ‚Üí (batch, 6)\n","        x = self.head(x)\n","\n","        # out: ‚Üí (batch, 6)\n","        return x\n","\n","def scope():\n","    m = SeparatedGRU().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["## separated GRU w/ montage"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# TODO: try 0.5 dropout\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, d_in, d_out, kernel_size, drop):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv1d(d_in, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.InstanceNorm1d(d_out),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.InstanceNorm1d(d_out),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.InstanceNorm1d(d_out),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0), # reduce sequence size by 2\n","        )\n","    def forward(self, x):\n","        # TODO: add skip for training speed\n","        return self.model(x)\n","        \n","class SeparatedGRU(nn.Module):\n","    def __init__(self, in_channels=4, gru_hidden_size=128, drop=0.2):\n","        super().__init__()\n","        self.d_split = len(GROUPS_IDS)\n","        self.pre_out = in_channels * 4\n","        self.gru_hidden_size = gru_hidden_size\n","        \n","        self.pre_process = nn.Sequential(\n","            nn.InstanceNorm1d(in_channels),\n","            # nn.LayerNorm(normalized_shape=[in_channels, 10000]),\n","            # nn.BatchNorm1d(in_channels, momentum=None),\n","            # use conv1d as a denoiser\n","            # -- block 1 --\n","            ConvBlock(in_channels, in_channels * 2, kernel_size=3, drop=drop),\n","            # nn.BatchNorm1d(in_channels * 2, momentum=None),\n","            # nn.LayerNorm(normalized_shape=[in_channels * 2, 5000]),\n","            # -- block 2 --\n","            ConvBlock(in_channels * 2, in_channels * 4, kernel_size=5, drop=drop),\n","            # nn.BatchNorm1d(in_channels * 4, momentum=None),\n","            # nn.LayerNorm(normalized_shape=[in_channels * 4, 2500]),\n","            # -- block 3 --\n","            ConvBlock(in_channels * 4, in_channels * 4, kernel_size=7, drop=drop),\n","            # nn.BatchNorm1d(in_channels * 4, momentum=None), # re-enable one more to force training ?\n","            # nn.LayerNorm(normalized_shape=[in_channels * 4, 1250]),\n","        )\n","        \n","        # TODO: add a learnable first state for GRU or check what is the default\n","        self.gru = nn.GRU(self.pre_out, self.gru_hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n","\n","        self.post_gru = nn.Sequential(\n","            # nn.BatchNorm1d(self.gru_hidden_size * 2, momentum=None),\n","            nn.LayerNorm(normalized_shape=[self.gru_hidden_size * 2]),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size * 2, self.gru_hidden_size),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size, self.gru_hidden_size),\n","        )\n","\n","        self.head = nn.Sequential(\n","            # nn.BatchNorm1d(self.gru_hidden_size * self.d_split, momentum=None),\n","            nn.LayerNorm(normalized_shape=[self.gru_hidden_size * self.d_split]),\n","            nn.Linear(self.gru_hidden_size * self.d_split, self.gru_hidden_size * 2),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size * 2, 6)\n","        )\n","\n","    def montage(self, x):\n","        splits = [x[:, :, group] for group in GROUPS_IDS]\n","        splits = [s[:, :, :-1] - s[:, :, 1:] for s in splits]\n","        return einops.rearrange(t.stack(splits, dim=0), 'group batch seq channel -> (group batch) seq channel')\n","\n","    def forward(self, x: ('batch', 'seq', 'channel')):\n","        # separate the input into 4 montages (LP, LL, RP, RR)\n","        x = self.montage(x)\n","        # pre_process: (batch, channel, seq) ‚Üí (batch / 4, channel * 4, seq)\n","        x = x.permute((0, 2, 1))\n","        x = self.pre_process(x)\n","        x = x.permute((0, 2, 1))\n","        # GRU: (batch, seq, input_size), [(2 * num_layers, batch, hidden_size)] ‚Üí (batch, seq, 2 * hidden_size)\n","        x, _ = self.gru(x)\n","        x = x[:, -1, :]\n","        # MLP post GRU\n","        x = self.post_gru(x)\n","        # unfold the splits\n","        x = einops.rearrange(x, '(group batch) hidden -> batch (hidden group)', group=self.d_split)\n","        # head: (batch, 2 * hidden_size) ‚Üí (batch, 6)\n","        x = self.head(x)\n","        # out: ‚Üí (batch, 6)\n","        return x\n","\n","def scope():\n","    m = SeparatedGRU().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["# train"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:22.709455Z","iopub.status.busy":"2024-03-21T21:37:22.709032Z","iopub.status.idle":"2024-03-21T21:37:24.020300Z","shell.execute_reply":"2024-03-21T21:37:24.019345Z","shell.execute_reply.started":"2024-03-21T21:37:22.709406Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model has 305118 params\n"]}],"source":["GC()\n","# model = Model().to(device)\n","# model = Transformer().to(device)\n","model = SeparatedGRU().to(device)\n","# TODO: try cranking the weight decay\n","# TODO: try using a scheduler\n","opt = t.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n","print(f'model has {sum(p.numel() for p in model.parameters())} params')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:24.022207Z","iopub.status.busy":"2024-03-21T21:37:24.021641Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0772dae6a6404c82bdb4d8d72cb9d3c8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2269 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeluche\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240327_201154-lvcly8er</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/lvcly8er' target=\"_blank\">wandering-monkey-89</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/lvcly8er' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/lvcly8er</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8bc155317234766a66f5d171316268c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2269 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def train(model, opt, wnb=True, data_augmentation=False):\n","    model.train()\n","    validation_test, validation_test_label = next(test_dataloader.__iter__())\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    limited_replay_buffer = []\n","    tq = tqdm(train_dataloader)\n","    for i, (x_train, y_train) in enumerate(tq):        \n","        limited_replay_buffer.append((x_train, y_train))\n","        if i > 1: break\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","    for epoch in range(1000):\n","        replay_buffer, maxi = [], 3\n","        tq = tqdm(train_dataloader)\n","        # for x_train, y_train in tq:\n","        for _ in range(1):\n","            # replay_buffer.append((x_train, y_train))\n","            # replay_buffer = replay_buffer[-maxi:]\n","            # XXX\n","            replay_buffer = limited_replay_buffer\n","            for x_train, y_train in replay_buffer: # burn more GPU otherwise we bottleneck on disk IO\n","            # for k in range(3): # the data reading is too slow, so force the GPU to spin\n","                if data_augmentation: x_train = augment_data(x_train)\n","                logs = model(x_train.to(device)).log_softmax(-1)\n","                kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","                loss = kl_loss(logs, y_train.to(device))\n","                opt.zero_grad()\n","                loss.backward()\n","                opt.step()\n","                tq.set_description(f'loss = {loss:.4f}')\n","                if wnb: wandb.log({'loss': loss.item()})\n","        \n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        if wnb:\n","            wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","            wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","        t.save(model.state_dict(), f'weights/gru-4-splits_{now}.pt')\n","    if wnb: wandb.finish()\n","\n","train(model, opt, wnb=True, data_augmentation=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeluche\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240327_061911-g5p2fxhm</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/g5p2fxhm' target=\"_blank\">amber-music-88</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/g5p2fxhm' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/g5p2fxhm</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a828f22511354d539ad19003b7e8b479","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abfd66849e8d4593a4f8e27d703a9078","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cda48dae42ad4ad69aed342879b49530","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd9de64c563247eb8f29745fdc378edc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5b4a37dd15041de8e4666b498b6bd8f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"980fd2cf2a9948c1acf72a546b5ffb10","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a27d98fe8ca46c7881dad0f016205d9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30d2ed05c39d4fc8a2333a6429617bcb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3944d1554bb486591a7a4126bf656fa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5e512fa96e14638a1e8682139d9560d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14ca2cc19a164627b285275c83c18648","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6b43d8035ca4041a4754a35643989ba","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47224a8cd50d4b6c8c9b773a8d87c814","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e66787a24ab3455ab77e59d152fb178d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35d2c6154eab4c1eb9ef0115d46d1d0e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"050b2ecd942846c9983da15bb794f2c2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b234930c1ddb4ad1a99f8c14fdb6c85e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7322ea3346f4d65bfdc0d9be5d3afc7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3209e47efcc140afa8b373314ddd0c03","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0bfb731f197e40078af9fd37cd9b13f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93006e9c98634598baed7c0ac78a1d56","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5c1ec3aafe14d09964a7415bcfb2631","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e3e1e1be14646a885baa296caea73be","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7fdfbdf2265b467c8bbc0db36931cdc2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77e17711435d45f1942ad80b6e5de38a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d94e057ee95413ca85ceeb4d255a6c4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7bac9af87c24411382d9fa285f971298","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06225ecdd96241679a1a6e6157163aed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4c753c3b5a3436d8a82f6dad247cc9c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e61f08cb4434479b17bb0a150167e76","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25fb965b3e444604b9a3af0f7c6e6bd7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43c7c9953aa9470ab687707788e9df65","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3331815f097842b4b18df1af40f023b5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24b9eb182062405fa20cc5f626fef79a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad515cc3cf0a407187d3abfb753992a7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"193416bd79694d6189282e85c0d2cd80","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45a15090c9e7428592da0e3588eb79f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a3ec6c7353b488facc49f8fb6102855","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75fd6e9128df434496edd8c157b0531d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e31124056b94a0aaaf0111489c15dac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db7aced85b974c9bb2513e8ed78ed7ab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26db55d41ca3443cb1d753f0bead35c8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"82cf662c1dee46c29e2e8cd1e0d01970","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e200644a2c8d407090ad3b65be32c651","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c57632996a9549f18c91691afc94ff8b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8e7a19c4b3a45e2a8644d1893e663fb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15c5b0ff1e4e44d7a7b4ac3155793c8d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b69c08030c3f4876a1897d933e821990","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8dcf942b5db493294838303f99aa42c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71259330e4914d6aafe95c7dd63c1c9c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b68ed20dfe76495bbcc45008310df0cf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c1c09d3f5eff454998df7730ad6443a5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31fbd18616014084b846efe3113205fa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6f6f7958d81446abf31ec51e532490c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc9047291a9b4e96be16119bca95efe5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34c1e81645124c6e9380de8d900e1861","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"945e6e40ed554a44966ac29b3d368fc1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96de1f6747b844409afb5df8c77d0854","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cbbef84d74574625acc19166ec6f4244","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac73392f6e614a718021f3dd18f68454","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ebda8485f3d47e5a89f8f325db32071","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b075629bb2343f9b47b5b90dee06284","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38a858c0ca904d99b47df4a93883ace6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4286aad18a9144e6a515ad082b36f1f3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae02180821d148b9b93c87201e577447","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18ae4a435cc4449c94c16d95a5447f85","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"772bff942d534c00bcf66c56724da99f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4210e10991504bc2a77b28a5220c3102","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c06cd789b1d443b9d0508536b03ce6a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1611584373034145b13e6199bc09991b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78c085216e344e5da83b8ffa14e64a68","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"484b36ef19a547c289e70b1205f17674","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"383c351576de459399b4984e2486a8cf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dba227d1f3644daebb811286e2e22c29","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c33c3edfb5df4cacb87a4a54022bc6c4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7132536a964f4515b5eecf43b66b33a8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c349315a80e44549f994ad19bec6739","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cda734391e5b4ef6b25daec5b6f67dfc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0594b3c194e043c68bc8becd938201a8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4bcc14c3ca7543118757d0facd6d1583","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45ed636b6ad14bb48830431294db86b6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c2a40b3a51f4a1ca024ef7e61f25fb8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34d0257e0e53459cb66b96fdc567fc01","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4853e0322524eb0aca6645ca08fa834","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca6c2ea796f14cabb3a84caef8229413","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95300d86cfbb445391c3df29ca50cd77","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"005096c62181457f9e19267ea97375a8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0a42347c2934ad3a6fc2b280949ea9b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab68d8da2167428baa2b79acb45387b1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f24ea2d31b524e0ab6ad91ea315a3abd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"572e2fadf9764624902a63642d1136bb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"266b7c751cb7466eb3c72517adfbe55b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7473d0e5603441578bb9657da04b55a9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5a990d189e1b4bb4b86d5be014d902dd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"375ad032a878425ab99de4a46eddc32d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b6c0c3247254184b35f9049a9fa599c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"887a7dc4409c4e348ff9582ce441d46d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8703be12663c408fbaa549192860db80","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4dd42e6d2607416ea98373323e005308","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e59d28905ec64119b0162545842568e3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5498509cc3d342ae88da1b3fa2b46fb8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af52d9fe975b447f855fb50703b45e43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15dd9f33172741928058f65c6278dce6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d6c86c1b77c4e57b9d6d3c10de067fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3546a6da7c48436cbbee692995bb0219","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e1e2ca4daf1422cb401168142ba0b3c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9fe9d2ed9dc464e9303254c6218f14b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8b16b823aef43869c26e0232bf323f0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e1f2697464b4874934f76b426fc1fec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24314de09ee44e2ea530b2e72f68231e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bc79b2603c140c0b51b3e77501b2f7a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24d8e771783341619718f5a6b8854faa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ba0fcf22ac94531bf999a413188c417","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbe1e0e0b333421ab11efa758f6b0964","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f93ab0435634313ab07ccdee31d4ce9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58e61d9a7e9e4e4fa617235252013f5f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2045a4fbb54b4987bb1e21e1b314bd1e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d45359b30b2047afbbd75f96acaffd10","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12b257f0fe5440ac8a85df7422a45fb8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6914d4ffa524413bef8e7ea240f0bd2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ddbb7defa834556a24b0e57c0619344","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95744e80a9c849d4b5f4e49e71108404","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ceeb90775804cdfb140125f869d91fc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2e6243be06d4ae7a7b0d40c4ee8f492","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"150bff064e99402dbd78040f79bb1513","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc0bc1f3218c4bdca13a293c64fa302a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78384eee98744fa3b6fb924cf29ed6ba","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c180607fe16f4e26901832f86ac788e2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f612dc0c1d14ab9bd3aa958268d0b75","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2251 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8aafd9e46624bcea6f9a3f0b0b0e4e1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e60fa724d014f219447a2d06eb6fe88","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"350518b0924a4f45aac42ca727284dd4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e31a130cca104c299af43d0e7853d94d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m replay_buffer\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m---> 43\u001b[0m \u001b[43mstaged_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwnb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[16], line 31\u001b[0m, in \u001b[0;36mstaged_train\u001b[0;34m(model, opt, mini_epochs, wnb, data_augmentation)\u001b[0m\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m kl_loss(logs, y_train\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     30\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem()})\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def populate_buffer(buffer_size=300):\n","    while True:\n","        limited_replay_buffer = []\n","        tq = tqdm(train_dataloader)\n","        for x_train, y_train in tq:\n","            limited_replay_buffer.append((x_train, y_train))\n","            if len(limited_replay_buffer) >= buffer_size:\n","                yield limited_replay_buffer\n","                del limited_replay_buffer\n","                limited_replay_buffer = []\n","\n","def staged_train(model, opt, mini_epochs, wnb=True, data_augmentation=False):\n","    model.train()\n","    validation_test, validation_test_label = next(test_dataloader.__iter__())\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","\n","    for replay_buffer in populate_buffer():\n","        for epoch in tqdm(range(mini_epochs)):\n","            for x_train, y_train in replay_buffer:\n","                if data_augmentation: x_train = augment_data(x_train)\n","                logs = model(x_train.to(device)).log_softmax(-1)\n","                kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","                loss = kl_loss(logs, y_train.to(device))\n","                opt.zero_grad()\n","                loss.backward()\n","                opt.step()\n","                if wnb: wandb.log({'loss': loss.item()})\n","        \n","            now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","            if wnb:\n","                wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","                wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","            t.save(model.state_dict(), f'weights/gru-4-splits_{now}.pt')\n","        del replay_buffer\n","    if wnb: wandb.finish()\n","\n","staged_train(model, opt, mini_epochs=20, wnb=True, data_augmentation=True)"]},{"cell_type":"markdown","metadata":{},"source":["# save / load"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# t.save(model.state_dict(),'model-weights4.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# model = SeparatedGRU().to(device)\n","# model.load_state_dict(t.load('weights/gru-4-splits_2024-03-24_15h03.pt', map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train(): train: 0.7416708129616388\n","train(): test:  0.7300541844123678\n","--\n","eval(): train   0.7619603112028007\n","eval(): test    0.8681249231237316\n"]}],"source":["x_train, y_train = next(train_dataloader.__iter__())\n","x_val, y_val = next(test_dataloader.__iter__())\n","\n","print(f'train(): train: {eval(model, x_train, y_train, do_eval=False)}')\n","print(f'train(): test:  {eval(model, x_val, y_val, do_eval=False)}')\n","print('--')\n","print(f'eval(): train   {eval(model, x_train, y_train, do_eval=True)}')\n","print(f'eval(): test    {eval(model, x_val, y_val, do_eval=True)}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# submit"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@t.no_grad()\n","def submit(model, test_dataloader, test_df):\n","    model.eval()\n","    res = []\n","    for batch in test_dataloader:\n","        prob = model(batch.to(device)).softmax(-1)\n","        res.append(prob.detach().cpu())\n","\n","    res = t.cat(res, dim=0)\n","    sub = test_df[[\"eeg_id\"]].copy()\n","    sub[TARGETS] = res\n","    sub.to_csv('submission.csv',index=False)\n","    print('Submission shape',sub.shape)\n","    display(sub.head())"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4638387,"sourceId":7898450,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
