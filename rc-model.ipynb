{"cells":[{"cell_type":"markdown","metadata":{},"source":["# imports"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-21T21:37:17.590772Z","iopub.status.busy":"2024-03-21T21:37:17.590059Z","iopub.status.idle":"2024-03-21T21:37:20.815655Z","shell.execute_reply":"2024-03-21T21:37:20.814795Z","shell.execute_reply.started":"2024-03-21T21:37:17.590738Z"},"trusted":true},"outputs":[],"source":["from datetime import datetime\n","import einops\n","import wandb\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt \n","from torch.utils.data import Dataset, DataLoader, random_split\n","import torch as t\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from functools import lru_cache\n","\n","device = 'cuda' if t.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["# utils"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.817280Z","iopub.status.busy":"2024-03-21T21:37:20.816807Z","iopub.status.idle":"2024-03-21T21:37:20.821939Z","shell.execute_reply":"2024-03-21T21:37:20.820711Z","shell.execute_reply.started":"2024-03-21T21:37:20.817254Z"},"trusted":true},"outputs":[],"source":["import gc \n","def GC():\n","    gc.collect()\n","    t.cuda.empty_cache()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["@t.no_grad()\n","def eval(model, x, y, do_eval=True):\n","    assert not x.isnan().any()\n","    assert not y.isnan().any()\n","    if do_eval: model.eval()\n","    else: model.train()\n","    logs = model(x.to(device)).log_softmax(-1)\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    loss = kl_loss(logs, y.to(device))\n","    model.train()\n","    return loss"]},{"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.824665Z","iopub.status.busy":"2024-03-21T21:37:20.824388Z","iopub.status.idle":"2024-03-21T21:37:20.832864Z","shell.execute_reply":"2024-03-21T21:37:20.831925Z","shell.execute_reply.started":"2024-03-21T21:37:20.824642Z"},"trusted":true},"outputs":[],"source":["batch_size = 50\n","prefetch_factor = 10\n","num_workers = 3"]},{"cell_type":"markdown","metadata":{},"source":["# data"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.834301Z","iopub.status.busy":"2024-03-21T21:37:20.834002Z","iopub.status.idle":"2024-03-21T21:37:20.842316Z","shell.execute_reply":"2024-03-21T21:37:20.841423Z","shell.execute_reply.started":"2024-03-21T21:37:20.834277Z"},"trusted":true},"outputs":[],"source":["test_path = './hms-harmful-brain-activity-classification/test_eegs/'\n","train_path = './hms-harmful-brain-activity-classification/train_eegs/'\n","BASE_PATH = \"./hms-harmful-brain-activity-classification\"\n","class_names = ['Seizure', 'LPD', 'GPD', 'LRDA','GRDA', 'Other']\n","FEATS_FOR_REAL = ['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n","#                   0      1     2     3     4     5     6     7     8     9    10     11    12    13    14    15    16    17    18    19\n","# group by semantic groups LP, LL, RP, RR https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Jan-2024/montage.png\n","# GROUPS = [\n","#     ['Fp1', 'F3', 'C3', 'P3', 'O1'],\n","#     ['Fp1', 'F7', 'T3', 'T5', 'O1'],\n","#     ['Fp2', 'F4', 'C4', 'P4', 'O2'],\n","#     ['Fp2', 'F8', 'T4', 'T6', 'O2'],\n","# ]\n","GROUPS_IDS = [\n","    [0, 1, 2, 3, 7],\n","    [0, 4, 5, 6, 7],\n","    [11, 12, 13, 14, 18],\n","    [11, 15, 16, 17, 18],\n","    # [8, 9, 10, 19] # TODO: try with leftovers?\n","]\n","# TODO: add frequency domain with fourier's transform\n","# TODO: add spectrogram to process with conv2d\n","# TODO: merge several models together\n","\n","TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\n","TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote','other_vote']"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.843552Z","iopub.status.busy":"2024-03-21T21:37:20.843247Z","iopub.status.idle":"2024-03-21T21:37:20.861786Z","shell.execute_reply":"2024-03-21T21:37:20.860812Z","shell.execute_reply.started":"2024-03-21T21:37:20.843528Z"},"trusted":true},"outputs":[],"source":["test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n","test_df['eeg_path'] = f'{BASE_PATH}/test_eegs/'+test_df['eeg_id'].astype(str)+'.parquet'\n","test_df['spec_path'] = f'{BASE_PATH}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.parquet'"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:20.864280Z","iopub.status.busy":"2024-03-21T21:37:20.863567Z","iopub.status.idle":"2024-03-21T21:37:21.129666Z","shell.execute_reply":"2024-03-21T21:37:21.128636Z","shell.execute_reply.started":"2024-03-21T21:37:20.864246Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","eeg_path = f'{BASE_PATH}/train_eegs/'+train_df['eeg_id'].astype(str)+'.parquet'\n","class_name = train_df.expert_consensus.copy()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:21.131192Z","iopub.status.busy":"2024-03-21T21:37:21.130854Z","iopub.status.idle":"2024-03-21T21:37:21.139945Z","shell.execute_reply":"2024-03-21T21:37:21.138915Z","shell.execute_reply.started":"2024-03-21T21:37:21.131165Z"},"trusted":true},"outputs":[],"source":["class Dataset(Dataset):\n","    def __init__(self, transform=None):\n","        super().__init__()\n","        self.dataframe = train_df\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    # @lru_cache(maxsize=None)\n","    def __getitem__(self, idx):\n","        row = self.dataframe.iloc[idx]\n","        eeg_id = row['eeg_id']\n","        parq_path = f'{train_path}{eeg_id}.parquet'\n","        eeg = pd.read_parquet(parq_path)\n","        start_time_second = row['eeg_label_offset_seconds']\n","        offset_dp = int(start_time_second * 200)\n","        duration = 10_000\n","    \n","        eeg = eeg.iloc[offset_dp:offset_dp+duration]\n","        eeg = eeg.ffill(axis=0)\n","        eeg = eeg.fillna(0)\n","        labels = row[TARGETS].values.astype(np.float64)\n","        labels = labels/np.sum(labels)\n","        samples = t.tensor(eeg[FEATS_FOR_REAL].values)\n","        labels_out = t.tensor(labels,dtype=t.float64)\n","        \n","        # assert not samples.isnan().any()\n","        # assert not labels_out.isnan().any()\n","        return samples, labels_out"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:21.141543Z","iopub.status.busy":"2024-03-21T21:37:21.141187Z","iopub.status.idle":"2024-03-21T21:37:21.159501Z","shell.execute_reply":"2024-03-21T21:37:21.158788Z","shell.execute_reply.started":"2024-03-21T21:37:21.141517Z"},"trusted":true},"outputs":[],"source":["dataset = Dataset()\n","train_size = int(len(dataset) * 0.9)\n","test_size = len(dataset) - train_size\n","# TODO: check for overlap because train and test seem to be too correlated compared to the leaderboard data\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# model ðŸ‘¯â€â™€ï¸"]},{"cell_type":"markdown","metadata":{},"source":["## conv1d + GRU"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:21.178778Z","iopub.status.busy":"2024-03-21T21:37:21.178518Z","iopub.status.idle":"2024-03-21T21:37:22.707099Z","shell.execute_reply":"2024-03-21T21:37:22.705508Z","shell.execute_reply.started":"2024-03-21T21:37:21.178755Z"},"trusted":true},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, d_in, d_out, kernel_size, drop):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv1d(d_in, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0), # reduce sequence size by 2\n","        )\n","    def forward(self, x):\n","        # TODO: add skip for training speed\n","        return self.model(x)\n","        \n","class Model(nn.Module):\n","    def __init__(self, in_channels=20, gru_hidden_size=128, drop=0.2):\n","        super().__init__()\n","        self.pre_out = in_channels * 4\n","        self.gru_hidden_size = gru_hidden_size\n","        \n","        self.pre_process = nn.Sequential(\n","            nn.BatchNorm1d(in_channels, momentum=None),\n","            # use conv1d as a denoiser\n","            # block 1\n","            ConvBlock(in_channels, in_channels * 2, kernel_size=3, drop=drop),\n","            nn.BatchNorm1d(in_channels * 2, momentum=None),\n","            \n","            # block 2\n","            ConvBlock(in_channels * 2, in_channels * 4, kernel_size=5, drop=drop),\n","            nn.BatchNorm1d(self.pre_out, momentum=None),\n","\n","            # block 3\n","            ConvBlock(in_channels * 4, in_channels * 4, kernel_size=7, drop=drop),\n","            nn.BatchNorm1d(self.pre_out, momentum=None),\n","        )\n","        \n","        # TODO: add a learnable first state for GRU or check what is the default\n","        self.gru = nn.GRU(self.pre_out, self.gru_hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n","\n","        self.head = nn.Sequential(\n","            nn.Linear(self.gru_hidden_size * 2, self.gru_hidden_size * 4),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size * 4, 6)\n","        )\n","\n","    def forward(self, x: ('batch', 'seq', 'channel')):\n","        # pre_process: (batch, channel, seq) â†’ (batch / 4, channel * 4, seq)\n","        x = x.permute((0, 2, 1))\n","        x = self.pre_process(x)\n","        x = x.permute((0, 2, 1))\n","\n","        # GRU: (batch, seq, input_size), [(2 * num_layers, batch, hidden_size)] â†’ (batch, seq, 2 * hidden_size)\n","        x, _ = self.gru(x)\n","        x = x[:, -1, :]\n","\n","        # head: (batch, 2 * hidden_size) â†’ (batch, 6)\n","        x = self.head(x)\n","\n","        # out: â†’ (batch, 6)\n","        return x\n","\n","def scope():\n","    m = Model().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["## transformer"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, d_chan=20, d_model=256, d_clump=4):\n","        super().__init__()\n","        self.d_clump = d_clump\n","\n","        self.start = nn.Parameter(t.randn(1, 1, d_model))\n","        self.bn = nn.BatchNorm1d(d_chan)\n","        self.emb = nn.Linear(d_chan * d_clump, d_model)\n","        self.llm = nn.Transformer(d_model=d_model, nhead=8, num_encoder_layers=3, num_decoder_layers=0, dim_feedforward=d_model * 2, batch_first=True)\n","        self.head = nn.Sequential(\n","            nn.Linear(d_model, d_model // 2),\n","            nn.ReLU(),\n","            nn.Linear(d_model // 2, 6)\n","        )\n","\n","    def forward(self, x):\n","        x = self.bn(x.permute((0, 2, 1))).permute((0, 2, 1))\n","        x = einops.rearrange(x, 'batch (seq clump) channels -> batch seq (clump channels)', clump=self.d_clump)\n","        x = self.emb(x)\n","        # add a fake start token\n","        x = t.cat([self.start.repeat(x.shape[0], 1, 1), x], dim=1)\n","        x = self.llm.encoder(x)[:, 0]\n","        return self.head(x)\n","\n","def scope():\n","    val, label = next(train_dataloader.__iter__())\n","    model = Transformer().to(device)\n","    output = model(val.to(device))\n","\n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["## separated GRU"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, d_in, d_out, kernel_size, drop):\n","        super().__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv1d(d_in, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Conv1d(d_out, d_out, kernel_size=kernel_size, padding='same', stride=1),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=0), # reduce sequence size by 2\n","        )\n","    def forward(self, x):\n","        # TODO: add skip for training speed\n","        return self.model(x)\n","        \n","class SeparatedGRU(nn.Module):\n","    def __init__(self, in_channels=5, gru_hidden_size=128, drop=0.1):\n","        super().__init__()\n","        self.d_split = len(GROUPS_IDS)\n","        self.pre_out = in_channels * 4\n","        self.gru_hidden_size = gru_hidden_size\n","        \n","        self.pre_process = nn.Sequential(\n","            nn.BatchNorm1d(in_channels, momentum=None),\n","            # use conv1d as a denoiser\n","            # block 1\n","            ConvBlock(in_channels, in_channels * 2, kernel_size=3, drop=drop),\n","            # nn.BatchNorm1d(in_channels * 2, momentum=None),\n","            \n","            # block 2\n","            ConvBlock(in_channels * 2, in_channels * 4, kernel_size=5, drop=drop),\n","            # nn.BatchNorm1d(self.pre_out, momentum=None),\n","\n","            # block 3\n","            ConvBlock(in_channels * 4, in_channels * 4, kernel_size=7, drop=drop),\n","            # nn.BatchNorm1d(self.pre_out, momentum=None),\n","        )\n","        \n","        # TODO: add a learnable first state for GRU or check what is the default\n","        self.gru = nn.GRU(self.pre_out, self.gru_hidden_size, num_layers=1, batch_first=True, bidirectional=True)\n","\n","        self.post_gru = nn.Sequential(\n","            nn.Linear(self.gru_hidden_size * 2, self.gru_hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(self.gru_hidden_size, self.gru_hidden_size),\n","        )\n","\n","        self.head = nn.Sequential(\n","            nn.Linear(self.gru_hidden_size * self.d_split, self.gru_hidden_size * 2),\n","            nn.ReLU(),\n","            nn.Dropout(drop),\n","            nn.Linear(self.gru_hidden_size * 2, 6)\n","        )\n","\n","    def forward(self, x: ('batch', 'seq', 'channel')):\n","        # separate the input into 4 splits (LP, LL, RP, RR)\n","        splits = [x[:, :, group] for group in GROUPS_IDS]\n","        # fold it into batch so we can run in parallel\n","        x = einops.rearrange(t.stack(splits, dim=0), 'group batch seq channel -> (group batch) seq channel')\n","\n","        # pre_process: (batch, channel, seq) â†’ (batch / 4, channel * 4, seq)\n","        x = x.permute((0, 2, 1))\n","        x = self.pre_process(x)\n","        x = x.permute((0, 2, 1))\n","\n","        # GRU: (batch, seq, input_size), [(2 * num_layers, batch, hidden_size)] â†’ (batch, seq, 2 * hidden_size)\n","        x, _ = self.gru(x)\n","        x = x[:, -1, :]\n","\n","        # MLP post GRU\n","        x = self.post_gru(x)\n","\n","        # unfold the splits\n","        x = einops.rearrange(x, '(group batch) hidden -> batch (hidden group)', group=self.d_split)\n","\n","        # head: (batch, 2 * hidden_size) â†’ (batch, 6)\n","        x = self.head(x)\n","\n","        # out: â†’ (batch, 6)\n","        return x\n","\n","def scope():\n","    m = SeparatedGRU().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# scope()"]},{"cell_type":"markdown","metadata":{},"source":["# train"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:22.709455Z","iopub.status.busy":"2024-03-21T21:37:22.709032Z","iopub.status.idle":"2024-03-21T21:37:24.020300Z","shell.execute_reply":"2024-03-21T21:37:24.019345Z","shell.execute_reply.started":"2024-03-21T21:37:22.709406Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model has 311788 params\n"]}],"source":["GC()\n","# model = Model().to(device)\n","# model = Transformer().to(device)\n","model = SeparatedGRU().to(device)\n","# TODO: try cranking the weight decay\n","# TODO: try using a scheduler\n","opt = t.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n","print(f'model has {sum(p.numel() for p in model.parameters())} params')"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-03-21T21:37:24.022207Z","iopub.status.busy":"2024-03-21T21:37:24.021641Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb5593294f83448ebb72cb015eab585e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"684f183cf3b14a868f4d63129c419fde","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dbcb6d83179c4b43b2063f3e7544eccc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59f2f6f5c6bf43df9bcb499711e78a3e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aaeebcf572f341cb9beaf648278d714c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ffa58fab89274534860e65f1afce7a6f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b60a0bf42ff845a4b87b21ed0e4ba70d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"02bad08f55b149b08968c044efbe8a10","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c18b4f21fc084b3ea12509d96a578020","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b4119eb29df3428aa2a056f95a184bf5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6515b1cc959c497db9e80b44ce9ab6e4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c15dc1434ffa46ea8fd883479e10e65e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d5f4995af1743bc9ba7a53e355846aa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23ea1a83d00e4ddca5858325f7de5231","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab7355c6624a4806a2c2863f5597d5ee","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"437aee802fe04a2286bf0394d36dcd43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47767068283544069ffff1136253ee7d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05e13fcf81f54ec3bd309a3cd3369c82","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6b28d04d60246fe8d1382d9ae654acf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf6446c120964d53b359fbc41b3af7ed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"212ec1d87db8468490cc4496475bd227","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"398cc6797b1f42dfa0492e64491d97d6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3cc55ebafaab47a198dd1e7d89265841","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fac62783aeb1496a83b6d23c412192f5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2841ba8f8b9740b897bee97ef332a630","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a14737ba3d4435382aa4cae5f0ce01d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18504a06bc4f428aa34a58e4f6e59294","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c363774ef37a4b24b72af0bfd02e3876","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66c9b9861f6040989336b2876a66844c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa5ab29ba16648bf8d89f56a0d2169fe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59b20839990549eb99871bf27ee2576f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79b9ca5780ee4491b20f43219aa1e855","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36df5c61937c4470a0a04906d88880fc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44cc3f012dea405fa08411c421ab4b95","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e379cbd244a744b0bcaa0bd6f68e9359","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7a4de8a1f584d90b7b353c7bd5ba5ea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9a55b5cb293423dbbf167545cf08b89","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bc852f65b7b44c02ab054ab7b3102d49","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b30b1d8897eb47f6a826cd603a29e80d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c39733d3cf80403293949017c232e951","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3c7f59ca50b4cd8aaf9b619aa20d1e2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca97401cdca947ceb1912ee6c061882d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2461f6aa2c5410d880fbfe7e574f33a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c57183672e3547b2a418d4ae59df7f80","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b73f7130fe954b82ab3c431e79a4bef4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29a925a47436462390f905fe7f36b815","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f403c7818c1484ca7a837d5c597b5c6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45d854b9687e47d3997a503b1bfe5054","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40962172b08c4ead83a6a19c8ad36222","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d92e3c34851f44a1b0d5ee202b84958e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a250d3e6f374e69babcf74cc44a80b9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd507740bbdb4128b82f3146c6b54fa1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"917af97c34cc47329a5c71f92132bd1b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e984673f772a4c32aa1c1bbf5f6c74cc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0807fadfcdab41829bfc5d2d682ad357","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"43c04bc21bf04ff5bab03b5928310dce","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"488e62cf26e843f58e057720b8ee3542","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c07fb61a40c44f0b5dfdd00e4969dd7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36782f3a7a5d433c98a81949292f6443","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f89a711b32e747429e1712309694a6a2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd394855a6554165a3f4341ecaf12f06","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eda3a40c4b99484f9d5613b6344257ae","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19de7c9cf91047e3b498b9bfcea9854d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7ce142866cd4f25b54b8f4f34758bf3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cadc777ee096432298911493f81fe6d9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1c116fbd9c54285a2b2f6501685aaef","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b49ef2381cb4db4bf77f6fcefe23040","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc7bf6061aaf4926bf2641d0226976c3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67203579cddf4c1182996945aa239604","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ad77b1c5e9e404298f638d6a7466964","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfb40eca67b647128ae1183b496825ac","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"026a8b341e674bd389443f330da4fae4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8d98c5817c64ded90cecfbc79ed0fbc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17ee3c834bb848a0ac53496f22397eb1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3d6dd3fba17491bb47983b4b3a89549","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1d939532db049dc9fae5cd4df4e8a03","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"11356695f159410081c5cf4867d873b6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd9c6cb38f26465d90b5d2a07c39039b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df79928dd0d74e0f9b5872dd59431099","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"997f23901ccf4ef6bb6bf062487e6656","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64ef1c28e9234522a5237d58a306d124","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbf736973cf04c039398a54ed36fb1a9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21f13ab376c343e9b955612b7c7aeb72","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30455a29069148cfb9fbd68669a64c7c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2eb1fd1fb064422a79bef61e87a7565","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"143556434d8941c698410ec03db518d3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2059544f10c74c0db8c1953060353f0c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"62b2450dbeb64468a1c2117698b5f505","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fad904cfa754792af8abb8947ed28ab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a63b559f1c6b437583178a04e46d0fe0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1923 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m         t\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights/gru-4-splits_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwnb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[17], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, opt, wnb, do_eval)\u001b[0m\n\u001b[1;32m      8\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m tq \u001b[38;5;241m=\u001b[39m tqdm(train_dataloader)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_train, y_train \u001b[38;5;129;01min\u001b[39;00m tq:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m): \u001b[38;5;66;03m# the data reading is too slow, so force the GPU to spin\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         logs \u001b[38;5;241m=\u001b[39m model(x_train\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n","File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n","File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n","File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n","File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def train(model, opt, wnb=True, do_eval=True):\n","    model.train()\n","    validation_test, validation_test_label = next(test_dataloader.__iter__())\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    # if wnb: wandb.init(project='kaggle-eeg-rc')\n","    for epoch in range(100):\n","        i = 0\n","        tq = tqdm(train_dataloader)\n","        for x_train, y_train in tq:\n","            for k in range(1): # the data reading is too slow, so force the GPU to spin\n","                logs = model(x_train.to(device)).log_softmax(-1)\n","                kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","                loss = kl_loss(logs, y_train.to(device))\n","                opt.zero_grad()\n","                loss.backward()\n","                opt.step()\n","                tq.set_description(f'loss = {loss:.4f}')\n","                if wnb: wandb.log({'loss': loss.item()})\n","        if wnb and do_eval:\n","            wandb.log({'validation_test-eval':   eval(model, validation_test, validation_test_label, do_eval=True)})\n","            wandb.log({'validation_test-train':  eval(model, validation_test, validation_test_label, do_eval=False)})\n","            wandb.log({'validation_train-eval':  eval(model, validation_train, validation_train_label, do_eval=True)})\n","            wandb.log({'validation_train-train': eval(model, validation_train, validation_train_label, do_eval=False)})\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        t.save(model.state_dict(), f'weights/gru-4-splits_{now}.pt')\n","    if wnb: wandb.finish()\n","\n","train(model, opt, wnb=True)"]},{"cell_type":"markdown","metadata":{},"source":["# save / load"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# t.save(model.state_dict(),'model-weights4.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# model = Model().to(device)\n","# model.load_state_dict(t.load('model-weights3.pt', map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x_train, y_train = next(train_dataloader.__iter__())\n","x_val, y_val = next(test_dataloader.__iter__())\n","\n","print(f'train.eval(): {eval(model, x_train, y_train, do_eval=True)}')\n","print(f'val.eval():  {eval(model, x_val, y_val, do_eval=True)}')\n","print('--')\n","print(f'train.train(): {eval(model, x_train, y_train, do_eval=False)}')\n","print(f'val.train():  {eval(model, x_val, y_val, do_eval=False)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["@t.no_grad()\n","def submit():\n","    model.eval()\n","    res = []\n","    # TODO: fix, read from the correct place instead\n","    for batch, labels in test_dataloader:\n","        batch = batch.to(device)\n","        prob = model(batch).softmax(-1)\n","        res.append(prob.detach().cpu())\n","        break\n","    res = t.cat(res, dim=0)\n","    print(res[0])\n","    \n","    pred_df = test_df[[\"eeg_id\"]].copy()\n","    target_cols = [x.lower()+'_vote' for x in class_names]\n","    pred_df[target_cols] = res.tolist()\n","    sub_df = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\n","    sub_df = sub_df[[\"eeg_id\"]].copy()\n","    sub_df = sub_df.merge(pred_df, on=\"eeg_id\", how=\"left\")\n","    sub_df.to_csv(\"submission.csv\", index=False)\n","    sub_df.head()\n","    \n","# submit()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4638387,"sourceId":7898450,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
