{"cells":[{"cell_type":"markdown","metadata":{},"source":["# imports"]},{"cell_type":"code","execution_count":82,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-29T18:57:28.868967Z","iopub.status.busy":"2024-03-29T18:57:28.868609Z","iopub.status.idle":"2024-03-29T18:57:34.421266Z","shell.execute_reply":"2024-03-29T18:57:34.420178Z","shell.execute_reply.started":"2024-03-29T18:57:28.868938Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'shutils'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[82], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutils\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# import einops\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shutils'"]}],"source":["from datetime import datetime\n","import shutils\n","import random\n","# import einops\n","import wandb\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt \n","from torch.utils.data import Dataset, DataLoader, random_split, Subset\n","import torch as t\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from functools import lru_cache\n","\n","device = 'cuda' if t.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["# utils"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:03:56.118424Z","iopub.status.busy":"2024-03-29T21:03:56.118030Z","iopub.status.idle":"2024-03-29T21:03:56.123348Z","shell.execute_reply":"2024-03-29T21:03:56.122133Z","shell.execute_reply.started":"2024-03-29T21:03:56.118389Z"},"trusted":true},"outputs":[],"source":["import gc \n","def GC():\n","    gc.collect()\n","    t.cuda.empty_cache()"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:13:57.721424Z","iopub.status.busy":"2024-03-29T21:13:57.721022Z","iopub.status.idle":"2024-03-29T21:13:57.729747Z","shell.execute_reply":"2024-03-29T21:13:57.728733Z","shell.execute_reply.started":"2024-03-29T21:13:57.721391Z"},"trusted":true},"outputs":[],"source":["# validation / inference loss\n","@t.no_grad()\n","def eval(model, x, y, do_eval=True):\n","    assert not x.isnan().any()\n","    assert not y.isnan().any()\n","    if do_eval: model.eval()\n","    else: model.train()\n","    logs = model(x.to(device)).log_softmax(-1)\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    loss = kl_loss(logs, y.to(device))\n","    model.train()\n","    return loss\n","\n","@t.no_grad()\n","def full_validation(model, dataloader):\n","    model.eval()\n","    card = 0\n","    loss = t.tensor(0.0).to(device)\n","    for x, y in dataloader:\n","        logs = model(x.to(device)).log_softmax(-1)\n","        kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","        # return kl_loss(logs, y.to(device))\n","        loss += kl_loss(logs, y.to(device)) * len(x)\n","        card += len(x)\n","    model.train()\n","    return loss / card"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:14:00.780275Z","iopub.status.busy":"2024-03-29T21:14:00.779611Z","iopub.status.idle":"2024-03-29T21:14:00.787552Z","shell.execute_reply":"2024-03-29T21:14:00.786385Z","shell.execute_reply.started":"2024-03-29T21:14:00.780241Z"},"trusted":true},"outputs":[],"source":["def noise(data, alpha):\n","    std = data.std(dim=(2, 3), keepdim=True)\n","    noise = t.randn_like(data, device=device) * std * alpha\n","    return data + noise\n","\n","def roll(data, shift):\n","    return t.roll(data, shifts=shift, dims=2)\n","\n","@t.no_grad()\n","def augment_data(data, alpha=0.1, shift=10):\n","    # data ‚Üí (batch, channel, seq, frequency) (e.g. (200, 4, 300, 100))\n","    data = data.to(device)\n","    data = noise(data, alpha)\n","    data = roll(data, shift)\n","    return data"]},{"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:45:07.285132Z","iopub.status.busy":"2024-03-29T20:45:07.284215Z","iopub.status.idle":"2024-03-29T20:45:07.289183Z","shell.execute_reply":"2024-03-29T20:45:07.288167Z","shell.execute_reply.started":"2024-03-29T20:45:07.285098Z"},"trusted":true},"outputs":[],"source":["batch_size = 55\n","# batch_size = 200\n","prefetch_factor = 10\n","num_workers = 3"]},{"cell_type":"markdown","metadata":{},"source":["# data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T19:06:20.062887Z","iopub.status.busy":"2024-03-29T19:06:20.062259Z","iopub.status.idle":"2024-03-29T19:06:20.071931Z","shell.execute_reply":"2024-03-29T19:06:20.070945Z","shell.execute_reply.started":"2024-03-29T19:06:20.062855Z"},"trusted":true},"outputs":[],"source":["train_path = './hms-harmful-brain-activity-classification/train_spectrograms/'\n","train_spec_path = './hms-harmful-brain-activity-classification/train_spectrograms/'\n","BASE_PATH = './hms-harmful-brain-activity-classification/'\n","PRE_PROCESSED_PATH = './spectrograms/'\n","\n","# TODO: merge several models together\n","# TODO: when submitting round values close to 0 to exactly 0 and rebalance the rest to sum() == 1 for free boost\n","\n","TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote','other_vote']"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def remove_overlaps(df, key='spectrogram_id'):\n","    ''' This makes the dataset 10x smaller, but it should be closer to the leaderboard '''\n","    return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:03:47.810752Z","iopub.status.busy":"2024-03-29T20:03:47.809848Z","iopub.status.idle":"2024-03-29T20:03:47.979640Z","shell.execute_reply":"2024-03-29T20:03:47.978834Z","shell.execute_reply.started":"2024-03-29T20:03:47.810718Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_2541408/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]}],"source":["train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","train_df = remove_overlaps(train_df)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:36:23.158813Z","iopub.status.busy":"2024-03-29T20:36:23.157986Z","iopub.status.idle":"2024-03-29T20:36:23.169504Z","shell.execute_reply":"2024-03-29T20:36:23.168569Z","shell.execute_reply.started":"2024-03-29T20:36:23.158779Z"},"trusted":true},"outputs":[],"source":["class Dataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","        self.dataframe = train_df\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    @lru_cache(maxsize=None)\n","    def __getitem__(self, idx): # preprocessed version\n","        row = self.dataframe.iloc[idx]\n","        id = row['spectrogram_id']\n","        sub_id = row['spectrogram_sub_id']\n","        path = f'{PRE_PROCESSED_PATH}/{id}_{sub_id}.pt'\n","        data = t.load(path)\n","        labels = row[TARGETS].values.astype(np.float64)\n","        labels = labels / np.sum(labels)\n","        labels_out = t.tensor(labels, dtype=t.float64)\n","        return data, labels_out"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T19:32:52.947658Z","iopub.status.busy":"2024-03-29T19:32:52.946745Z","iopub.status.idle":"2024-03-29T19:32:52.955390Z","shell.execute_reply":"2024-03-29T19:32:52.954371Z","shell.execute_reply.started":"2024-03-29T19:32:52.947619Z"},"trusted":true},"outputs":[],"source":["# def plot_spectogram(spec_df, prefixes, title = \"Spectogram\"):\n","#     fig = sp.make_subplots(rows=len(prefixes), cols=1, subplot_titles=prefixes)\n","#     for i, prefix in enumerate(prefixes):\n","#         prefix_df = spec_df.filter(regex=f'^{prefix}', axis=1)\n","#         epsilon = 1e-10\n","#         fig.add_trace(go.Heatmap(z=np.log(prefix_df + epsilon).T,\n","#                                  y=pd.to_numeric(prefix_df.columns.str.replace(f\"{prefix}_\", '')),\n","#                                  coloraxis=\"coloraxis\"),\n","#                       row=i+1, col=1)\n","#          # Update x-axis and y-axis labels\n","#         fig.update_xaxes(title_text=\"Time(Seconds)\", row=i+1, col=1)\n","#         fig.update_yaxes(title_text=\"Frequency(Hz)\", row=i+1, col=1)\n","#         # update coloraxis\n","#         fig.update_layout(coloraxis = {'colorscale':'Jet'}, height=1500,title_text=title)\n","#     fig.show()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:45:11.990547Z","iopub.status.busy":"2024-03-29T20:45:11.989709Z","iopub.status.idle":"2024-03-29T20:45:12.016792Z","shell.execute_reply":"2024-03-29T20:45:12.015864Z","shell.execute_reply.started":"2024-03-29T20:45:11.990515Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(10581, 557)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dataset = Dataset()\n","ids = train_df['spectrogram_id'].unique()\n","np.random.shuffle(ids)\n","split = int(len(ids) * 0.95)\n","\n","train_ids = ids[:split]\n","test_ids = ids[split:]\n","\n","now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","t.save(t.tensor(train_ids), f'./splits/{now}_train_ids.pt')\n","t.save(t.tensor(train_ids), f'./splits/{now}_test_ids.pt')\n","\n","train_indices = train_df[train_df['spectrogram_id'].isin(train_ids)].index.tolist()\n","test_indices = train_df[train_df['spectrogram_id'].isin(test_ids)].index.tolist()\n","\n","train_dataset = Subset(dataset, train_indices)\n","test_dataset = Subset(dataset, test_indices)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","\n","len(train_dataset), len(test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# model üëØ‚Äç‚ôÄÔ∏è"]},{"cell_type":"markdown","metadata":{},"source":["## conv1d + GRU"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["((1, 2, 3), (1, 2, 3), (1, 2, 3))"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["(*[(1, 2, 3) for _ in range(3)], )"]},{"cell_type":"code","execution_count":126,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:02:35.320633Z","iopub.status.busy":"2024-03-29T21:02:35.320217Z","iopub.status.idle":"2024-03-29T21:02:40.982361Z","shell.execute_reply":"2024-03-29T21:02:40.981275Z","shell.execute_reply.started":"2024-03-29T21:02:35.320600Z"},"trusted":true},"outputs":[],"source":["class CNNSkipBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, repeat, dropout, stride=1):\n","        super(CNNSkipBlock, self).__init__()\n","        self.pre = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding='same', padding_mode='reflect')\n","        self.convs = nn.Sequential(\n","            *(nn.Sequential(\n","                nn.LeakyReLU(),\n","                nn.Dropout(dropout),\n","                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding='same', padding_mode='reflect')) \n","            for _ in range(repeat)),\n","        )\n","        self.post = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","    def forward(self, x):\n","        x = self.pre(x)\n","        x = x + self.convs(x) # weird skip\n","        return self.post(x)\n","\n","class CNNBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, dropout, stride=1):\n","        super(CNNBlock, self).__init__()\n","        downsample = in_channels != out_channels\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding='same', padding_mode='reflect'),\n","            # nn.BatchNorm2d(out_channels), # TODO: I hate batchnorm -_-\n","            nn.LeakyReLU(),\n","            nn.Dropout(dropout),\n","            *(nn.MaxPool2d(kernel_size=2, stride=2),) if downsample else (),\n","            # *(nn.InstanceNorm2d(out_channels, affine=True),) if downsample else (),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","        \n","class Model(nn.Module):\n","    # def __init__(self, convs=[4, 64, 64, 128, 128, 256, 256, 256, 257, 257, 257, 258, 258, 258, 259], hidden=512, dropout=0.4):\n","    def __init__(self, convs=[4, 8, 8, 8, 8, 16, 16, 16, 16, 32, 32, 32, 32, 64, 64, 64, 128, 128, 128, 259], hidden=256, dropout=0.1):\n","    # def __init__(self, convs=[4, 30, 30, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 64, 64, 64, 128, 128, 128, 259], hidden=256, dropout=0.2):\n","    # def __init__(self, convs=[4, 45, 45, 45, 45, 64, 64, 64, 64, 90, 90, 90, 90, 127, 127, 127, 128, 128, 128, 259], hidden=256, dropout=0.2):\n","    # def __init__(self, convs=[4, 45, 45, 45, 45, 64, 64, 64, 64, 90, 90, 90, 90, 128, 128, 128, 256, 256, 256, 259], hidden=256, dropout=0.2):\n","    # def __init__(self, convs=[4, 8, 8, 8, 16, 16, 16, 32, 32, 32, 32, 64, 64, 64, 128, 128, 256], hidden=512, dropout=0.5):\n","    # def __init__(self, convs=[4, 8, 8, 8, 8, 8, 16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 64, 64, 64, 128, 259], hidden=256, dropout=0.4):\n","    # def __init__(self, convs=[4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 64, 64, 64, 128, 259], hidden=256, dropout=0.4):\n","    # def __init__(self, convs=[4, 8, 8, 8, 16, 16, 16, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64, 128, 128, 128, 259], hidden=256, dropout=0.4):\n","    # def __init__(self, convs_b=[4, 8, 16, 32, 64, 128, 256], repeat=3, hidden=256, dropout=0.5):\n","        super().__init__()\n","\n","        # self.cnn = nn.Sequential(\n","        #     *[CNNSkipBlock(in_chan, out_chan, repeat=repeat, dropout=dropout) for in_chan, out_chan in zip(convs_b, convs_b[1:])]\n","        # )\n","        self.cnn = nn.Sequential(\n","            *[CNNBlock(in_chan, out_chan, dropout=dropout) for in_chan, out_chan in zip(convs, convs[1:])]\n","        )\n","        self.head = nn.Sequential(\n","            nn.Flatten(start_dim=1, end_dim=-1),\n","            nn.Linear(259 * 4, hidden),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden, hidden),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden, 6),\n","        )\n","\n","    def forward(self, x):\n","        x = self.cnn(x)\n","        # print(x.shape)\n","        x = self.head(x)\n","        return x\n","\n","def test():\n","    m = Model().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    print(f'{x.shape=}')\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# test()"]},{"cell_type":"markdown","metadata":{},"source":["# train"]},{"cell_type":"code","execution_count":127,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:04:08.985271Z","iopub.status.busy":"2024-03-29T21:04:08.984919Z","iopub.status.idle":"2024-03-29T21:04:11.427419Z","shell.execute_reply":"2024-03-29T21:04:11.426486Z","shell.execute_reply.started":"2024-03-29T21:04:08.985245Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model has 1135369 params\n"]}],"source":["GC()\n","model = Model().to(device)\n","# opt = t.optim.Adam(model.parameters(), lr=3e-4, weight_decay=3e-5)\n","opt = t.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n","# opt = t.optim.LBFGS(model.parameters(), lr=3e-4, max_iter=20, max_eval=20, history_size=100, line_search_fn='strong_wolfe')\n","scheduler = t.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.95, patience=10)\n","print(f'model has {sum(p.numel() for p in model.parameters())} params')"]},{"cell_type":"markdown","metadata":{},"source":["## LBFGS"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"data":{"text/html":["Finishing last run (ID:9lkuddqa) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fc74ac90ce34402a5d44caed30e2605","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ</td></tr><tr><td>val_test</td><td>‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>val_train</td><td>‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>6.513299214705998e+28</td></tr><tr><td>now</td><td>2024-03-31_23h27</td></tr><tr><td>val_test</td><td>7.360023609887224e+28</td></tr><tr><td>val_train</td><td>4.460541716934729e+28</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">crimson-eon-173</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/9lkuddqa' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/9lkuddqa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240331_232614-9lkuddqa/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:9lkuddqa). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42a04db3878a478db1ff8affd650e611","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112558756334085, max=1.0‚Ä¶"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240331_232812-b1e1bgjv</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/b1e1bgjv' target=\"_blank\">effortless-universe-174</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/b1e1bgjv' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/b1e1bgjv</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1799e31e5454d6680c86e9cbfb40de9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d00403de8f94529881e0fd9e3cb2d57","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/193 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c27d11352e814a0cba89f63758bcd23d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/193 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18f89386cd5f4e6d99061678a5e47157","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/193 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[66], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m         t\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights/cnn_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m---> 36\u001b[0m \u001b[43mmemory_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwnb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[66], line 26\u001b[0m, in \u001b[0;36mmemory_train\u001b[0;34m(model, opt, wnb, data_augmentation)\u001b[0m\n\u001b[1;32m     24\u001b[0m         nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[0;32m---> 26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem()})\n\u001b[1;32m     29\u001b[0m now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mHh\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lbfgs.py:428\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[0;32m--> 428\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m    431\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lbfgs.py:99\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[0;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[1;32m     97\u001b[0m g_prev \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[1;32m     98\u001b[0m gtd_prev \u001b[38;5;241m=\u001b[39m gtd_new\n\u001b[0;32m---> 99\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m ls_func_evals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    101\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lbfgs.py:426\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[0;34m(x, t, d)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lbfgs.py:280\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[0;34m(self, closure, x, t, d)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m--> 280\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    281\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[66], line 23\u001b[0m, in \u001b[0;36mmemory_train.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m kl_loss(logs, y_train\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     22\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def memory_lbfgs_train(model, opt, wnb=True, data_augmentation=False):\n","    model.train()\n","    validation_test, validation_test_label = next(test_dataloader.__iter__())\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","\n","    for epoch in tqdm(range(100000)):\n","        for x_train, y_train in tqdm(train_dataloader):\n","            # TODO: use variable alpha based on mini_epoch\n","            if data_augmentation: x_train = augment_data(x_train,\n","                                                         alpha=random.choice([0.01, 0.05, 0.1, 0.15]), #, 0.2])) #, 0.3]))\n","                                                         shift=random.choice(list(range(30))))\n","            def closure():\n","                logs = model(x_train.to(device)).log_softmax(-1)\n","                kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","                loss = kl_loss(logs, y_train.to(device))\n","                opt.zero_grad()\n","                loss.backward()\n","                nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n","                return loss\n","            loss = opt.step(closure)\n","            if wnb: wandb.log({'loss': loss.item()})\n","    \n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        if wnb:\n","            wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","            wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","        t.save(model.state_dict(), f'weights/cnn_{now}.pt')\n","    if wnb: wandb.finish()\n","\n","# memory_lbfgs_train(model, opt, wnb=True, data_augmentation=True)"]},{"cell_type":"markdown","metadata":{},"source":["## in memory"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[{"data":{"text/html":["Finishing last run (ID:9fcj121y) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5813db6d1d3406cab58f7c6ece0477a","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.2964237433943714, max=1.0‚Ä¶"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ</td></tr><tr><td>patience</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÇ‚ñÉ</td></tr><tr><td>val_test</td><td>‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>val_train</td><td>‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.68398</td></tr><tr><td>now</td><td>2024-04-01_16h09</td></tr><tr><td>patience</td><td>13</td></tr><tr><td>val_test</td><td>1.07358</td></tr><tr><td>val_train</td><td>0.82687</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">polar-elevator-187</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/9fcj121y' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/9fcj121y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240401_155039-9fcj121y/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:9fcj121y). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45f4a6a04a6642a68af69caf8618c9c5","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111278655524883, max=1.0)‚Ä¶"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240401_161008-55fgawg2</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/55fgawg2' target=\"_blank\">earnest-forest-188</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/55fgawg2' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/55fgawg2</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1eb586eb9dbf4933b782e8fa8837f7d5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["rollback to checkpoint 2024-04-01_16h19\n","rollback to checkpoint 2024-04-01_16h26\n","rollback to checkpoint 2024-04-01_16h30\n","rollback to checkpoint 2024-04-01_16h34\n","rollback to checkpoint 2024-04-01_16h38\n","rollback to checkpoint 2024-04-01_16h43\n","rollback to checkpoint 2024-04-01_16h47\n","rollback to checkpoint 2024-04-01_16h52\n","rollback to checkpoint 2024-04-01_16h57\n","rollback to checkpoint 2024-04-01_17h01\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[128], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m             scheduler\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m---> 57\u001b[0m \u001b[43mmemory_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwnb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[128], line 15\u001b[0m, in \u001b[0;36mmemory_train\u001b[0;34m(model, opt, wnb, data_augmentation, patience)\u001b[0m\n\u001b[1;32m     11\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_train\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;28meval\u001b[39m(model, validation_train, validation_train_label, do_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnow\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100000\u001b[39m)):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# for x_train, y_train in tqdm(train_dataloader):\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_train, y_train \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# TODO: use variable alpha based on mini_epoch\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data_augmentation: x_train \u001b[38;5;241m=\u001b[39m augment_data(x_train,\n\u001b[1;32m     18\u001b[0m                                                      alpha\u001b[38;5;241m=\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.15\u001b[39m]), \u001b[38;5;66;03m#, 0.2])) #, 0.3]))\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                                                      shift\u001b[38;5;241m=\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m))))\n\u001b[1;32m     20\u001b[0m         logs \u001b[38;5;241m=\u001b[39m model(x_train\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:168\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m elem\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;129;01min\u001b[39;00m {torch\u001b[38;5;241m.\u001b[39msparse_coo, torch\u001b[38;5;241m.\u001b[39msparse_csr, torch\u001b[38;5;241m.\u001b[39msparse_bsr, torch\u001b[38;5;241m.\u001b[39msparse_csc, torch\u001b[38;5;241m.\u001b[39msparse_bsc}:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches of sparse tensors are not currently supported by the default collate_fn; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease provide a custom collate_fn to handle them appropriately.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m     )\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_worker_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# If we're in a background process, concatenate directly into a\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# shared memory tensor to avoid an extra copy\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     numel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(x\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch)\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py:89\u001b[0m, in \u001b[0;36mget_worker_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m             items\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[38;5;250m \u001b[39mk)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(items)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_worker_info\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[WorkerInfo]:\n\u001b[1;32m     90\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the information about the current\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch.utils.data.DataLoader` iterator worker process.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m       code.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _worker_info\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def memory_train(model, opt, wnb=True, data_augmentation=False, patience=50):\n","    model.train()\n","    patience_counter = 0\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        best_validation_loss = full_validation(model, test_dataloader)\n","        wandb.log({'val_test':   best_validation_loss, 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","\n","    for epoch in tqdm(range(100000)):\n","        # for x_train, y_train in tqdm(train_dataloader):\n","        for x_train, y_train in train_dataloader:\n","            # TODO: use variable alpha based on mini_epoch\n","            if data_augmentation: x_train = augment_data(x_train,\n","                                                         alpha=random.choice([0.01, 0.05, 0.1, 0.15]), #, 0.2])) #, 0.3]))\n","                                                         shift=random.choice(list(range(30))))\n","            logs = model(x_train.to(device)).log_softmax(-1)\n","            kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","            loss = kl_loss(logs, y_train.to(device))\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            if wnb: wandb.log({'loss': loss.item()})\n","    \n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        validation_loss = full_validation(model, test_dataloader)\n","        scheduler.step(validation_loss)\n","        if wnb:\n","            wandb.log({'val_test': validation_loss, 'now': f'{now}'})\n","            wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","        # checkpoint and rollback\n","        # Note: this is a form of polution of the validation set\n","        if validation_loss < best_validation_loss:\n","            best_validation_loss = validation_loss\n","            patience_counter = 0\n","            t.save(model.state_dict(), f'weights/best_{now}_{validation_loss:.2f}.pt')\n","            t.save({\n","                'model': model.state_dict(),\n","                'opt': opt.state_dict(),\n","                'scheduler': scheduler.state_dict(),\n","            },  'best_checkpoint.pt')\n","        else: patience_counter += 1\n","        if wnb: wandb.log({'patience': patience_counter})\n","        if patience_counter > patience:\n","            print(f'rollback to checkpoint {now}')\n","            patience_counter = 0\n","            checkpoint = t.load('best_checkpoint.pt')\n","            model.load_state_dict(checkpoint['model'])\n","            opt.load_state_dict(checkpoint['opt'])\n","            scheduler.load_state_dict(checkpoint['scheduler'])\n","        \n","    if wnb: wandb.finish()\n","\n","memory_train(model, opt, wnb=True, data_augmentation=True)"]},{"cell_type":"markdown","metadata":{},"source":["## staged"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:14:10.391136Z","iopub.status.busy":"2024-03-29T21:14:10.390404Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeluche\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240330_045624-5ovufe8f</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/5ovufe8f' target=\"_blank\">golden-planet-124</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/5ovufe8f' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/5ovufe8f</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e55b3b4c5202440f8bb5d22cc47b3244","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1856 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bae63f61eef84200ab8e248bc7f38f99","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76daa9dbdc864a01a93d5df2d1e5f809","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"701144bd19114c5da93840cfecebec18","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m replay_buffer\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m---> 47\u001b[0m \u001b[43mstaged_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwnb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[15], line 33\u001b[0m, in \u001b[0;36mstaged_train\u001b[0;34m(model, opt, mini_epochs, wnb, data_augmentation)\u001b[0m\n\u001b[1;32m     31\u001b[0m logs \u001b[38;5;241m=\u001b[39m model(x_train\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mKLDivLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m loss \u001b[38;5;241m=\u001b[39m kl_loss(logs, \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def populate_buffer(buffer_size=300):\n","    while True:\n","        limited_replay_buffer = []\n","        tq = tqdm(train_dataloader)\n","        for x_train, y_train in tq:\n","            limited_replay_buffer.append((x_train, y_train))\n","            if len(limited_replay_buffer) >= buffer_size:\n","                yield limited_replay_buffer\n","                del limited_replay_buffer\n","                limited_replay_buffer = []\n","\n","def staged_train(model, opt, mini_epochs, wnb=True, data_augmentation=False):\n","    model.train()\n","    validation_test, validation_test_label = next(test_dataloader.__iter__())\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","\n","    # rb = [next(iter(train_dataloader))]\n","    # for _ in range(1000):\n","        # replay_buffer = rb\n","    for replay_buffer in populate_buffer():\n","        for epoch in tqdm(range(mini_epochs)):\n","            for x_train, y_train in replay_buffer:\n","                # TODO: use variable alpha based on mini_epoch\n","                if data_augmentation: x_train = augment_data(x_train, alpha=random.choice([0.01, 0.05, 0.1])) #, 0.15, 0.2, 0.3]))\n","                logs = model(x_train.to(device)).log_softmax(-1)\n","                kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","                loss = kl_loss(logs, y_train.to(device))\n","                opt.zero_grad()\n","                loss.backward()\n","                opt.step()\n","                if wnb: wandb.log({'loss': loss.item()})\n","        \n","            now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","            if wnb:\n","                wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","                wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","            t.save(model.state_dict(), f'weights/gru-4-splits_{now}.pt')\n","        del replay_buffer\n","    if wnb: wandb.finish()\n","\n","# staged_train(model, opt, mini_epochs=20, wnb=True, data_augmentation=True)"]},{"cell_type":"markdown","metadata":{},"source":["# save / load"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# t.save(model.state_dict(),'model-weights4.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# model = SeparatedGRU().to(device)\n","# model.load_state_dict(t.load('weights/gru-4-splits_2024-03-24_15h03.pt', map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train(): train: 0.3067223824690105\n","\n","train(): test:  0.7667477726504927\n","\n","--\n","\n","eval(): train   0.38911351894595714\n","\n","eval(): test    0.7780192006451506\n"]}],"source":["x_train, y_train = next(train_dataloader.__iter__())\n","x_val, y_val = next(test_dataloader.__iter__())\n","\n","print(f'train(): train: {eval(model, x_train, y_train, do_eval=False)}')\n","print(f'train(): test:  {eval(model, x_val, y_val, do_eval=False)}')\n","print('--')\n","print(f'eval(): train   {eval(model, x_train, y_train, do_eval=True)}')\n","print(f'eval(): test    {eval(model, x_val, y_val, do_eval=True)}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# submit"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@t.no_grad()\n","def submit(model, test_dataloader, test_df):\n","    model.eval()\n","    res = []\n","    for batch in test_dataloader:\n","        prob = model(batch.to(device)).softmax(-1)\n","        res.append(prob.detach().cpu())\n","\n","    res = t.cat(res, dim=0)\n","    sub = test_df[[\"eeg_id\"]].copy()\n","    sub[TARGETS] = res\n","    sub.to_csv('submission.csv',index=False)\n","    print('Submission shape',sub.shape)\n","    display(sub.head())"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4638387,"sourceId":7898450,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
