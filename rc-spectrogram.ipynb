{"cells":[{"cell_type":"markdown","metadata":{},"source":["# kaggle: HMS - Harmful Brain Activity Classification\n","- https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification"]},{"cell_type":"markdown","metadata":{},"source":["# models\n","## EEG (time domain)\n","- treat it as a sequence problem using:\n","  - conv1d\n","  - conv1d + GRU\n","  - transformer\n","## Spectrogram (frequency domain)\n","- treat it as an image problem using conv2d + MLP\n","\n","# training\n","- split train 0.95 / valid 0.05 \n","- minibatch, evaluate valid at each epoch, log everything to wandb\n","- minibatch repeated\n","- replay buffer of mini batch\n","- LBFGS (horrible because I can't do full batch)\n","- train 3 models and average the results (annoyingly better results)\n","- scheduler for the LR\n","- snapshot and auto rollback after patience is exhausted\n","\n","# data\n","- data cleaning (remove NaN, fill with average or zero)\n","- exclude data that overlap from training to validation\n","- exclude data with weird bias (less experts predictions)\n","- montage of electrodes (https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4308868%2Ff790d9fba9d01f39b5c688819cc90f64%2Ftileshop.jpg?generation=1705166531784497&alt=media\n","\n","# overfit\n","- weight decay with AdamW\n","- dropout\n","- data augmentation (add some 0.1 std() noise)\n","- early stoppage / constant snapshot the model and pick based on curve\n","\n","# \"underfit\"\n","- batchnorm was horrible, it makes it look like it train, but it does not generalize well at all in .eval(), only in .train()\n","- change layer sizes\n","- change depth of layers\n","- tried skip connections\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["# imports"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-29T18:57:28.868967Z","iopub.status.busy":"2024-03-29T18:57:28.868609Z","iopub.status.idle":"2024-03-29T18:57:34.421266Z","shell.execute_reply":"2024-03-29T18:57:34.420178Z","shell.execute_reply.started":"2024-03-29T18:57:28.868938Z"},"trusted":true},"outputs":[],"source":["from datetime import datetime\n","import random\n","import wandb\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt \n","from torch.utils.data import Dataset, DataLoader, random_split, Subset\n","import torch as t\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from functools import lru_cache\n","\n","device = 'cuda' if t.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["# utils"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:03:56.118424Z","iopub.status.busy":"2024-03-29T21:03:56.118030Z","iopub.status.idle":"2024-03-29T21:03:56.123348Z","shell.execute_reply":"2024-03-29T21:03:56.122133Z","shell.execute_reply.started":"2024-03-29T21:03:56.118389Z"},"trusted":true},"outputs":[],"source":["import gc \n","def GC():\n","    gc.collect()\n","    t.cuda.empty_cache()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:13:57.721424Z","iopub.status.busy":"2024-03-29T21:13:57.721022Z","iopub.status.idle":"2024-03-29T21:13:57.729747Z","shell.execute_reply":"2024-03-29T21:13:57.728733Z","shell.execute_reply.started":"2024-03-29T21:13:57.721391Z"},"trusted":true},"outputs":[],"source":["# validation / inference loss\n","@t.no_grad()\n","def eval(model, x, y, do_eval=True):\n","    assert not x.isnan().any()\n","    assert not y.isnan().any()\n","    if do_eval: model.eval()\n","    else: model.train()\n","    logs = model(x.to(device)).log_softmax(-1)\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    loss = kl_loss(logs, y.to(device))\n","    model.train()\n","    return loss\n","\n","@t.no_grad()\n","def full_validation(model, dataloader):\n","    model.eval()\n","    card = 0\n","    loss = t.tensor(0.0).to(device)\n","    for x, y in dataloader:\n","        logs = model(x.to(device)).log_softmax(-1)\n","        kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","        loss += kl_loss(logs, y.to(device)) * len(x)\n","        card += len(x)\n","    model.train()\n","    return loss / card\n","\n","@t.no_grad()\n","def multi_model_full_validation(models, dataloader):\n","    for model in models: model.eval()\n","    card = 0\n","    loss = t.tensor(0.0).to(device)\n","    for x, y in dataloader:\n","        logs = []\n","        for model in models:\n","            logs.append(model(x.to(device)).log_softmax(-1))\n","        logs = t.stack(logs).mean(dim=0)\n","        kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","        loss += kl_loss(logs, y.to(device)) * len(x)\n","        card += len(x)\n","    for model in models: model.train()\n","    return loss / card    "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:14:00.780275Z","iopub.status.busy":"2024-03-29T21:14:00.779611Z","iopub.status.idle":"2024-03-29T21:14:00.787552Z","shell.execute_reply":"2024-03-29T21:14:00.786385Z","shell.execute_reply.started":"2024-03-29T21:14:00.780241Z"},"trusted":true},"outputs":[],"source":["def noise(data, alpha):\n","    std = data.std(dim=(2, 3), keepdim=True)\n","    noise = t.randn_like(data, device=device) * std * alpha\n","    return data + noise\n","\n","def roll(data, shift):\n","    return t.roll(data, shifts=shift, dims=2)\n","\n","@t.no_grad()\n","def augment_data(data, alpha=0.1, shift=10):\n","    # data → (batch, channel, seq, frequency) (e.g. (200, 4, 300, 100))\n","    data = data.to(device)\n","    data = noise(data, alpha)\n","    data = roll(data, shift)\n","    return data"]},{"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:45:07.285132Z","iopub.status.busy":"2024-03-29T20:45:07.284215Z","iopub.status.idle":"2024-03-29T20:45:07.289183Z","shell.execute_reply":"2024-03-29T20:45:07.288167Z","shell.execute_reply.started":"2024-03-29T20:45:07.285098Z"},"trusted":true},"outputs":[],"source":["batch_size = 55\n","prefetch_factor = 10\n","num_workers = 3"]},{"cell_type":"markdown","metadata":{},"source":["# data"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# train_df[TARGETS].head()"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","# train_df = remove_overlaps(train_df)\n","# train_df[TARGETS].sum(axis=1).hist()"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["spectrogram_id\n","764146759     1022\n","1974785580     836\n","1391458063     743\n","1863712617     703\n","577118473      562\n","840003147      534\n","365931891      531\n","12849827       449\n","1568768668     444\n","1254544437     440\n","Name: count, dtype: int64"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","# train_df = remove_overlaps(train_df)\n","# (train_df[TARGETS].sum(axis=1) > 7).sum()\n","# train_df[['spectrogram_id', 'spectrogram_sub_id']].values[:10]\n","train_df['spectrogram_id'].value_counts().sort_values(ascending=False).head(10)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T19:06:20.062887Z","iopub.status.busy":"2024-03-29T19:06:20.062259Z","iopub.status.idle":"2024-03-29T19:06:20.071931Z","shell.execute_reply":"2024-03-29T19:06:20.070945Z","shell.execute_reply.started":"2024-03-29T19:06:20.062855Z"},"trusted":true},"outputs":[],"source":["train_path = './hms-harmful-brain-activity-classification/train_spectrograms/'\n","train_spec_path = './hms-harmful-brain-activity-classification/train_spectrograms/'\n","BASE_PATH = './hms-harmful-brain-activity-classification/'\n","PRE_PROCESSED_PATH = './spectrograms/'\n","TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote','other_vote']"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def remove_overlaps(df, key='spectrogram_id'):\n","    ''' This makes the dataset 10x smaller, but it should be closer to the leaderboard '''\n","    return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:03:47.810752Z","iopub.status.busy":"2024-03-29T20:03:47.809848Z","iopub.status.idle":"2024-03-29T20:03:47.979640Z","shell.execute_reply":"2024-03-29T20:03:47.978834Z","shell.execute_reply.started":"2024-03-29T20:03:47.810718Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3083955/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]}],"source":["train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","train_df = remove_overlaps(train_df)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:36:23.158813Z","iopub.status.busy":"2024-03-29T20:36:23.157986Z","iopub.status.idle":"2024-03-29T20:36:23.169504Z","shell.execute_reply":"2024-03-29T20:36:23.168569Z","shell.execute_reply.started":"2024-03-29T20:36:23.158779Z"},"trusted":true},"outputs":[],"source":["class Dataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","        self.dataframe = train_df\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    @lru_cache(maxsize=None)\n","    def __getitem__(self, idx): # preprocessed version\n","        row = self.dataframe.iloc[idx]\n","        id = row['spectrogram_id']\n","        sub_id = row['spectrogram_sub_id']\n","        path = f'{PRE_PROCESSED_PATH}/{id}_{sub_id}.pt'\n","        data = t.load(path)\n","        labels = row[TARGETS].values.astype(np.float64)\n","        labels = labels / np.sum(labels)\n","        labels_out = t.tensor(labels, dtype=t.float64)\n","        return data, labels_out"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T19:32:52.947658Z","iopub.status.busy":"2024-03-29T19:32:52.946745Z","iopub.status.idle":"2024-03-29T19:32:52.955390Z","shell.execute_reply":"2024-03-29T19:32:52.954371Z","shell.execute_reply.started":"2024-03-29T19:32:52.947619Z"},"trusted":true},"outputs":[],"source":["# def plot_spectogram(spec_df, prefixes, title = \"Spectogram\"):\n","#     fig = sp.make_subplots(rows=len(prefixes), cols=1, subplot_titles=prefixes)\n","#     for i, prefix in enumerate(prefixes):\n","#         prefix_df = spec_df.filter(regex=f'^{prefix}', axis=1)\n","#         epsilon = 1e-10\n","#         fig.add_trace(go.Heatmap(z=np.log(prefix_df + epsilon).T,\n","#                                  y=pd.to_numeric(prefix_df.columns.str.replace(f\"{prefix}_\", '')),\n","#                                  coloraxis=\"coloraxis\"),\n","#                       row=i+1, col=1)\n","#          # Update x-axis and y-axis labels\n","#         fig.update_xaxes(title_text=\"Time(Seconds)\", row=i+1, col=1)\n","#         fig.update_yaxes(title_text=\"Frequency(Hz)\", row=i+1, col=1)\n","#         # update coloraxis\n","#         fig.update_layout(coloraxis = {'colorscale':'Jet'}, height=1500,title_text=title)\n","#     fig.show()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","# train_df = remove_overlaps(train_df)\n","# train_indices = train_df[train_df['spectrogram_id'].isin(train_ids)].index.tolist()\n","# test_indices = train_df[train_df['spectrogram_id'].isin(test_ids)].index.tolist()\n","# train_dataset = Subset(dataset, train_indices)\n","# test_dataset = Subset(dataset, test_indices)\n","\n","# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:45:11.990547Z","iopub.status.busy":"2024-03-29T20:45:11.989709Z","iopub.status.idle":"2024-03-29T20:45:12.016792Z","shell.execute_reply":"2024-03-29T20:45:12.015864Z","shell.execute_reply.started":"2024-03-29T20:45:11.990515Z"},"trusted":true},"outputs":[],"source":["dataset = Dataset()\n","ids = train_df['spectrogram_id'].unique()\n","np.random.shuffle(ids)\n","split = int(len(ids) * 0.95)\n","\n","train_ids = ids[:split]\n","test_ids = ids[split:]\n","\n","now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","t.save(t.tensor(train_ids), f'./splits/{now}_train_ids.pt')\n","t.save(t.tensor(train_ids), f'./splits/{now}_test_ids.pt')\n","\n","# train_indices = train_df[train_df['spectrogram_id'].isin(train_ids)].index.tolist()\n","# test_indices = train_df[train_df['spectrogram_id'].isin(test_ids)].index.tolist()\n","\n","# train_dataset = Subset(dataset, train_indices)\n","# test_dataset = Subset(dataset, test_indices)\n","\n","# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","# test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","# # train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","# # test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","\n","# len(train_dataset), len(test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# model 👯‍♀️"]},{"cell_type":"markdown","metadata":{},"source":["## conv2d"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:02:35.320633Z","iopub.status.busy":"2024-03-29T21:02:35.320217Z","iopub.status.idle":"2024-03-29T21:02:40.982361Z","shell.execute_reply":"2024-03-29T21:02:40.981275Z","shell.execute_reply.started":"2024-03-29T21:02:35.320600Z"},"trusted":true},"outputs":[],"source":["class CNNSkipBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, repeat, dropout, stride=1):\n","        super(CNNSkipBlock, self).__init__()\n","        self.pre = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding='same', padding_mode='reflect')\n","        self.convs = nn.Sequential(\n","            *(nn.Sequential(\n","                nn.LeakyReLU(),\n","                nn.Dropout(dropout),\n","                nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding='same', padding_mode='reflect')) \n","            for _ in range(repeat)),\n","        )\n","        self.post = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","    def forward(self, x):\n","        x = self.pre(x)\n","        x = x + self.convs(x) # weird skip\n","        return self.post(x)\n","\n","class CNNBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, dropout, stride=1):\n","        super(CNNBlock, self).__init__()\n","        downsample = in_channels != out_channels\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding='same', padding_mode='reflect'),\n","            # nn.BatchNorm2d(out_channels), # TODO: I hate batchnorm -_-\n","            nn.LeakyReLU(),\n","            nn.Dropout(dropout),\n","            # *(nn.MaxPool2d(kernel_size=2, stride=2),) if downsample else (),\n","            *(nn.AvgPool2d(kernel_size=2, stride=2),) if downsample else (),\n","            # *(nn.InstanceNorm2d(out_channels, affine=True),) if downsample else (),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","        \n","class Model(nn.Module):\n","    # def __init__(self, convs=[4, 64, 64, 128, 128, 256, 256, 256, 257, 257, 257, 258, 258, 258, 259], hidden=512, dropout=0.4):\n","    # def __init__(self, convs=[4, 8, 8, 8, 8, 16, 16, 16, 16, 32, 32, 32, 32, 64, 64, 64, 128, 128, 128, 259], hidden=256, dropout=0.1):\n","    def __init__(self, convs=[4, 30, 30, 30, 30, 31, 31, 31, 31, 32, 32, 32, 32, 64, 64, 64, 128, 128, 128, 259], hidden=256, dropout=0.1):\n","    # def __init__(self, convs=[4, 45, 45, 45, 45, 64, 64, 64, 64, 90, 90, 90, 90, 127, 127, 127, 128, 128, 128, 259], hidden=256, dropout=0.2):\n","    # def __init__(self, convs=[4, 45, 45, 45, 45, 64, 64, 64, 64, 90, 90, 90, 90, 128, 128, 128, 256, 256, 256, 259], hidden=256, dropout=0.2):\n","    # def __init__(self, convs=[4, 8, 8, 8, 16, 16, 16, 32, 32, 32, 32, 64, 64, 64, 128, 128, 256], hidden=512, dropout=0.5):\n","    # def __init__(self, convs=[4, 8, 8, 8, 8, 8, 16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 64, 64, 64, 128, 259], hidden=256, dropout=0.4):\n","    # def __init__(self, convs=[4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 64, 64, 64, 128, 259], hidden=256, dropout=0.4):\n","    # def __init__(self, convs=[4, 8, 8, 8, 16, 16, 16, 32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64, 128, 128, 128, 259], hidden=256, dropout=0.4):\n","    # def __init__(self, convs_b=[4, 8, 16, 32, 64, 128, 256], repeat=3, hidden=256, dropout=0.5):\n","        super().__init__()\n","\n","        # self.cnn = nn.Sequential(\n","        #     *[CNNSkipBlock(in_chan, out_chan, repeat=repeat, dropout=dropout) for in_chan, out_chan in zip(convs_b, convs_b[1:])]\n","        # )\n","        self.cnn = nn.Sequential(\n","            *[CNNBlock(in_chan, out_chan, dropout=dropout) for in_chan, out_chan in zip(convs, convs[1:])]\n","        )\n","        self.head = nn.Sequential(\n","            nn.Flatten(start_dim=1, end_dim=-1),\n","            nn.Linear(259 * 4, hidden),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden, hidden),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden, 6),\n","        )\n","\n","    def forward(self, x):\n","        x = self.cnn(x)\n","        # print(x.shape)\n","        x = self.head(x)\n","        return x\n","\n","def test():\n","    m = Model().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    print(f'{x.shape=}')\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# test()"]},{"cell_type":"markdown","metadata":{},"source":["# train"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:04:08.985271Z","iopub.status.busy":"2024-03-29T21:04:08.984919Z","iopub.status.idle":"2024-03-29T21:04:11.427419Z","shell.execute_reply":"2024-03-29T21:04:11.426486Z","shell.execute_reply.started":"2024-03-29T21:04:08.985245Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model has 1189454 params\n"]}],"source":["GC()\n","model = Model().to(device)\n","# opt = t.optim.Adam(model.parameters(), lr=3e-4, weight_decay=3e-5)\n","opt = t.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n","# opt = t.optim.LBFGS(model.parameters(), lr=3e-4, max_iter=20, max_eval=20, history_size=100, line_search_fn='strong_wolfe')\n","scheduler = t.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.95, patience=10)\n","print(f'model has {sum(p.numel() for p in model.parameters())} params')"]},{"cell_type":"markdown","metadata":{},"source":["## LBFGS"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def memory_lbfgs_train(model, opt, wnb=True, data_augmentation=False):\n","    model.train()\n","    validation_test, validation_test_label = next(test_dataloader.__iter__())\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","\n","    for epoch in tqdm(range(100000)):\n","        for x_train, y_train in tqdm(train_dataloader):\n","            # TODO: use variable alpha based on mini_epoch\n","            if data_augmentation: x_train = augment_data(x_train,\n","                                                         alpha=random.choice([0.01, 0.05, 0.1, 0.15]), #, 0.2])) #, 0.3]))\n","                                                         shift=random.choice(list(range(30))))\n","            def closure():\n","                logs = model(x_train.to(device)).log_softmax(-1)\n","                kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","                loss = kl_loss(logs, y_train.to(device))\n","                opt.zero_grad()\n","                loss.backward()\n","                nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n","                return loss\n","            loss = opt.step(closure)\n","            if wnb: wandb.log({'loss': loss.item()})\n","    \n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        if wnb:\n","            wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","            wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","        t.save(model.state_dict(), f'weights/cnn_{now}.pt')\n","    if wnb: wandb.finish()\n","\n","# memory_lbfgs_train(model, opt, wnb=True, data_augmentation=True)"]},{"cell_type":"markdown","metadata":{},"source":["## fold train"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3083955/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]},{"data":{"text/html":["Finishing last run (ID:qcrukmzu) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"149fedc0a5734308a65d230741a3dd2c","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▇██▇█▇▆▄▆▅▃▄▅▅▄▅▄▅▃▄▄▃▄▃▄▂▃▃▃▃▄▃▄▁▁▃▃▃▂▃</td></tr><tr><td>patience</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▂▃▃▄▄▅▅▆▆▇▇▇█▁▁▂▂▃▃▄▄</td></tr><tr><td>val_test</td><td>█▆▆▆▅▅▅▃▄▃▂▂▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▂▂▂▁▂▂▂</td></tr><tr><td>val_train</td><td>█▆▆▆▆▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.67743</td></tr><tr><td>now</td><td>2024-04-02_07h24</td></tr><tr><td>patience</td><td>18</td></tr><tr><td>val_test</td><td>0.85183</td></tr><tr><td>val_train</td><td>0.70417</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">smooth-microwave-199</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/qcrukmzu' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/qcrukmzu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240402_071010-qcrukmzu/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:qcrukmzu). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6020a47d54a747d5b0ddf5d9761b1d65","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112785388508604, max=1.0…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240402_072705-j3ohecki</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/j3ohecki' target=\"_blank\">northern-star-200</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/j3ohecki' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/j3ohecki</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65fbc50b20f046659dad2f0b710a1fcb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b261eb2110e47f0b8f0ccf9826dcc23","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.298810703666997, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▇▆▆▅▅▅▄▄▂▄▄▃▅▂▂▂▂▂▂▂▄▃▂▄▂▂▂▃▂▁▂▂▂▁▃▁▃▁</td></tr><tr><td>patience</td><td>▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▂▂▁▂▂▃▁▂▂▂▃▃▄▄▅▅▆▆▇▇▇█</td></tr><tr><td>val_test</td><td>█▆▅▅▄▄▃▃▂▃▂▂▂▂▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁</td></tr><tr><td>val_train</td><td>█▇▇▆▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.70575</td></tr><tr><td>now</td><td>2024-04-02_07h40</td></tr><tr><td>patience</td><td>39</td></tr><tr><td>val_test</td><td>0.80626</td></tr><tr><td>val_train</td><td>0.48119</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">northern-star-200</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/j3ohecki' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/j3ohecki</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240402_072705-j3ohecki/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3083955/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240402_074023-w7j8fcrf</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/w7j8fcrf' target=\"_blank\">solar-wood-201</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/w7j8fcrf' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/w7j8fcrf</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc5bd8f209984966b1ac4740818d9932","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aac0af5d661d4106a5cdb606d114dbcd","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▇█▇▆▅▆▇▅▅▅▄▆▅▄▃▄▃▂▄▄▃▂▂▃▃▂▂▃▂▂▂▂▁▁▂▄▂▂▁▂</td></tr><tr><td>patience</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▂▁▂▂▃▄▁▂▃▃▄▄▅▅▆▇▇█</td></tr><tr><td>val_test</td><td>█▆▆▆▅▄▃▅▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▁▂▁▁▂▇▂▁▁▂▁</td></tr><tr><td>val_train</td><td>▇▇▆▇▆▅▅▅▄▄▄▄▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂█▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.32897</td></tr><tr><td>now</td><td>2024-04-02_07h53</td></tr><tr><td>patience</td><td>30</td></tr><tr><td>val_test</td><td>0.80191</td></tr><tr><td>val_train</td><td>0.42112</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">solar-wood-201</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/w7j8fcrf' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/w7j8fcrf</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240402_074023-w7j8fcrf/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3083955/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240402_075322-vhjb4mb1</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/vhjb4mb1' target=\"_blank\">tough-yogurt-202</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/vhjb4mb1' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/vhjb4mb1</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e58a8ca37974ef48836a5dac585e1a6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aed483b66cc74381bebc699d406f898f","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.29009377254147634, max=1.…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>███▇▆▆▆▆▅▅▅▆▃▅▄▄▃▃▃▄▃▂▃▁▃▃▄▂▃▃▂▄▁▄▃▂▃▂▁▁</td></tr><tr><td>patience</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>val_test</td><td>█▆▅▅▅▄▄▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁▂▁▁▁</td></tr><tr><td>val_train</td><td>█▆▆▅▅▅▄▄▄▄▃▄▃▃▃▃▃▂▂▃▃▂▃▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.59794</td></tr><tr><td>now</td><td>2024-04-02_08h06</td></tr><tr><td>patience</td><td>49</td></tr><tr><td>val_test</td><td>0.88638</td></tr><tr><td>val_train</td><td>0.61213</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">tough-yogurt-202</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/vhjb4mb1' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/vhjb4mb1</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240402_075322-vhjb4mb1/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3083955/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240402_080619-p0kdv4my</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/p0kdv4my' target=\"_blank\">scarlet-pyramid-203</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/p0kdv4my' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/p0kdv4my</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2920214a9f944375a3dca8831a6bcecf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ca02eb8a8f546f194755dabeb2eb984","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.29012865215823014, max=1.…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▇███▇▆▅▄▆▄▃▆▄▄▄▂▄▃▂▄▅▃▅▁▁▂▂▂▃▁▂▁▁▁▃▃▁▁▂▂</td></tr><tr><td>patience</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>val_test</td><td>█▆▆▆▅▅▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂</td></tr><tr><td>val_train</td><td>█▇▇▇▆▅▅▄▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.63486</td></tr><tr><td>now</td><td>2024-04-02_08h19</td></tr><tr><td>patience</td><td>50</td></tr><tr><td>val_test</td><td>0.81422</td></tr><tr><td>val_train</td><td>0.37457</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">scarlet-pyramid-203</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/p0kdv4my' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/p0kdv4my</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240402_080619-p0kdv4my/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3083955/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240402_081918-7c8m83sd</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/7c8m83sd' target=\"_blank\">giddy-elevator-204</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/7c8m83sd' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/7c8m83sd</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c41312d10e5a491284e70581644f9dec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6071fe37f13944e59a09d5be2cc417d1","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.298897559767125, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██▇▇▇▇▅▅▄▄▅▃▃▄▄▃▂▃▅▂▄▂▄▄▄▅▆▂▂▄▃▃▂▂▂▁▃▃▃▁</td></tr><tr><td>patience</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▁▁▁▂▁▁▂▃▄▅▆▁▂▃▄▅▆▇█▁▂▂▁▂▃</td></tr><tr><td>val_test</td><td>█▆▆▅▅▄▃▃▃▂▂▂▂▂▂▂▁▁▂▁▁▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>val_train</td><td>█▇▇▇▇▆▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.6436</td></tr><tr><td>now</td><td>2024-04-02_08h32</td></tr><tr><td>patience</td><td>6</td></tr><tr><td>val_test</td><td>0.79302</td></tr><tr><td>val_train</td><td>0.55769</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">giddy-elevator-204</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/7c8m83sd' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/7c8m83sd</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240402_081918-7c8m83sd/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3083955/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240402_083210-qbmrbp11</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/qbmrbp11' target=\"_blank\">deep-grass-205</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/qbmrbp11' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/qbmrbp11</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0f85c48c856475285c566debea6b176","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8193350f51f84125bfd05af06d8f8a49","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.298897559767125, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██▇▇▆▆▇▆▄▅▆▄▅▅▄▅▄▄▄▄▄▃▄▃▃▃▃▄▂▂▃▄▃▄▃▂▁▁▂▂</td></tr><tr><td>patience</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▃▄▄▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>val_test</td><td>█▆▆▅▅▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▂▂▂▂▂▂▂▁▂▂</td></tr><tr><td>val_train</td><td>█▆▆▆▆▆▆▆▆▄▄▃▄▃▄▃▂▂▂▁▂▂▂▂▂▂▁▁▁▂▁▂▂▂▂▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.52066</td></tr><tr><td>now</td><td>2024-04-02_08h44</td></tr><tr><td>patience</td><td>29</td></tr><tr><td>val_test</td><td>0.88679</td></tr><tr><td>val_train</td><td>0.50224</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">deep-grass-205</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/qbmrbp11' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/qbmrbp11</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240402_083210-qbmrbp11/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3083955/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240402_084505-9eulrnb8</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/9eulrnb8' target=\"_blank\">exalted-silence-206</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/9eulrnb8' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/9eulrnb8</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48a2e1ef0c9441cb898d7ab76253c31e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"211efac388fd4a1e95c7e2a4ccedc282","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▇▇█▆▇▆▆▄▅▄▅▄▄▄▄▃▃▃▂▂▃▃▄▂▃▁▂▃▂▁▁▃▂▂▂▂▂▂▂▂</td></tr><tr><td>patience</td><td>▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▂▂▃▄▄▁▂▁▂▃▄▄▅▅▂▂▃▄▄▅▆▆▇█</td></tr><tr><td>val_test</td><td>█▆▆▆▅▅▄▄▄▃▂▂▂▁▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▂▁▁▁</td></tr><tr><td>val_train</td><td>█▅▅▅▅▅▄▄▄▃▃▃▂▃▂▂▂▃▂▂▂▂▂▁▂▂▂▂▁▂▁▁▁▂▁▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.67547</td></tr><tr><td>now</td><td>2024-04-02_08h57</td></tr><tr><td>patience</td><td>25</td></tr><tr><td>val_test</td><td>0.82097</td></tr><tr><td>val_train</td><td>0.41155</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">exalted-silence-206</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/9eulrnb8' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/9eulrnb8</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240402_084505-9eulrnb8/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["def fold_train(model, opt, fold, wnb=True, data_augmentation=False, patience=50, epochs=100):\n","    model.train()\n","\n","    GC()\n","    train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","    train_df = remove_overlaps(train_df)\n","    train_indices = train_df[train_df['spectrogram_id'].isin(train_ids)].index.tolist()\n","    test_indices = train_df[train_df['spectrogram_id'].isin(test_ids)].index.tolist()\n","    train_dataset = Subset(dataset, train_indices)\n","    test_dataset = Subset(dataset, test_indices)\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","\n","    patience_counter = 0\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        best_validation_loss = full_validation(model, test_dataloader)\n","        wandb.log({'val_test':   best_validation_loss, 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","\n","    for epoch in tqdm(range(epochs)):\n","        # for x_train, y_train in tqdm(train_dataloader):\n","        for x_train, y_train in train_dataloader:\n","            # TODO: use variable alpha based on mini_epoch\n","            if data_augmentation: x_train = augment_data(x_train,\n","                                                         alpha=random.choice([0.01, 0.05, 0.1]), #, 0.15, 0.2])) #, 0.3]))\n","                                                         shift=random.choice(list(range(30))))\n","            logs = model(x_train.to(device)).log_softmax(-1)\n","            kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","            loss = kl_loss(logs, y_train.to(device))\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            if wnb: wandb.log({'loss': loss.item()})\n","    \n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        validation_loss = full_validation(model, test_dataloader)\n","        scheduler.step(validation_loss)\n","        if wnb:\n","            wandb.log({'val_test': validation_loss, 'now': f'{now}'})\n","            wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","        # checkpoint and rollback\n","        # Note: this is a form of polution of the validation set\n","        if validation_loss < best_validation_loss:\n","            best_validation_loss = validation_loss\n","            patience_counter = 0\n","            t.save(model.state_dict(), f'weights/best_{now}_{validation_loss:.2f}.pt')\n","            t.save(model.state_dict(), f'fold/best_{fold}.pt')\n","            t.save({\n","                'model': model.state_dict(),\n","                'opt': opt.state_dict(),\n","                'scheduler': scheduler.state_dict(),\n","            },  'best_checkpoint.pt')\n","        else: patience_counter += 1\n","        if wnb: wandb.log({'patience': patience_counter})\n","        if patience_counter > patience:\n","            print(f'rollback to checkpoint {now}')\n","            patience_counter = 0\n","            checkpoint = t.load('best_checkpoint.pt')\n","            model.load_state_dict(checkpoint['model'])\n","            opt.load_state_dict(checkpoint['opt'])\n","            scheduler.load_state_dict(checkpoint['scheduler'])\n","        \n","    if wnb: wandb.finish()\n","\n","def start_fold_train(folds, epochs):\n","    for fold in range(folds):\n","        GC()\n","        model = Model().to(device)\n","        opt = t.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n","        scheduler = t.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.95, patience=10)\n","        fold_train(model, opt, fold, wnb=True, data_augmentation=True, epochs=epochs)\n","\n","start_fold_train(folds=7, epochs=100)"]},{"cell_type":"markdown","metadata":{},"source":["## in memory"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["Finishing last run (ID:rjab5xys) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db46c146007449ffac1b88ba1cc35f56","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▆▆▅▆▅▄▄▃▅▄▅▅▄▆▄▇▅▅▃▄▆▅▃▄▄▇▅▆▂▅▆▆▃▃▇▁▆▅</td></tr><tr><td>patience</td><td>▁▁▁▁▁▂▁▁▁▂▁▁▂▁▁▂▁▂▃▃▁▂▃▁▂▁▃▃▄▅▆▇█▁▂▃▄▅▆▇</td></tr><tr><td>val_test</td><td>█▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_train</td><td>█▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>1.21436</td></tr><tr><td>now</td><td>2024-04-01_17h17</td></tr><tr><td>patience</td><td>8</td></tr><tr><td>val_test</td><td>1.27496</td></tr><tr><td>val_train</td><td>1.30325</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">drawn-gorge-189</strong> at: <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/rjab5xys' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/rjab5xys</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240401_170512-rjab5xys/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:rjab5xys). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff2b41b51ffb4360a1a11e69c7ee7797","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111266898870882, max=1.0)…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240401_171809-m1mbzs26</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/m1mbzs26' target=\"_blank\">pleasant-dust-190</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/m1mbzs26' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/m1mbzs26</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"34070b09ab354559b429bb45299b47ed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/100000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["rollback to checkpoint 2024-04-01_17h45\n","rollback to checkpoint 2024-04-01_18h07\n","rollback to checkpoint 2024-04-01_18h19\n","rollback to checkpoint 2024-04-01_18h32\n","rollback to checkpoint 2024-04-01_18h44\n","rollback to checkpoint 2024-04-01_18h56\n","rollback to checkpoint 2024-04-01_19h09\n","rollback to checkpoint 2024-04-01_19h21\n","rollback to checkpoint 2024-04-01_19h33\n","rollback to checkpoint 2024-04-01_19h46\n","rollback to checkpoint 2024-04-01_19h58\n","rollback to checkpoint 2024-04-01_20h10\n","rollback to checkpoint 2024-04-01_20h22\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[134], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m             scheduler\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m---> 57\u001b[0m \u001b[43mmemory_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwnb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[134], line 15\u001b[0m, in \u001b[0;36mmemory_train\u001b[0;34m(model, opt, wnb, data_augmentation, patience)\u001b[0m\n\u001b[1;32m     11\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_train\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;28meval\u001b[39m(model, validation_train, validation_train_label, do_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnow\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100000\u001b[39m)):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# for x_train, y_train in tqdm(train_dataloader):\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_train, y_train \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# TODO: use variable alpha based on mini_epoch\u001b[39;00m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data_augmentation: x_train \u001b[38;5;241m=\u001b[39m augment_data(x_train,\n\u001b[1;32m     18\u001b[0m                                                      alpha\u001b[38;5;241m=\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice([\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.15\u001b[39m]), \u001b[38;5;66;03m#, 0.2])) #, 0.3]))\u001b[39;00m\n\u001b[1;32m     19\u001b[0m                                                      shift\u001b[38;5;241m=\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m))))\n\u001b[1;32m     20\u001b[0m         logs \u001b[38;5;241m=\u001b[39m model(x_train\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:144\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def memory_train(model, opt, wnb=True, data_augmentation=False, patience=50):\n","    model.train()\n","    patience_counter = 0\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        best_validation_loss = full_validation(model, test_dataloader)\n","        wandb.log({'val_test':   best_validation_loss, 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","\n","    for epoch in tqdm(range(100000)):\n","        # for x_train, y_train in tqdm(train_dataloader):\n","        for x_train, y_train in train_dataloader:\n","            # TODO: use variable alpha based on mini_epoch\n","            if data_augmentation: x_train = augment_data(x_train,\n","                                                         alpha=random.choice([0.01, 0.05, 0.1, 0.15]), #, 0.2])) #, 0.3]))\n","                                                         shift=random.choice(list(range(30))))\n","            logs = model(x_train.to(device)).log_softmax(-1)\n","            kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","            loss = kl_loss(logs, y_train.to(device))\n","            opt.zero_grad()\n","            loss.backward()\n","            opt.step()\n","            if wnb: wandb.log({'loss': loss.item()})\n","    \n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        validation_loss = full_validation(model, test_dataloader)\n","        scheduler.step(validation_loss)\n","        if wnb:\n","            wandb.log({'val_test': validation_loss, 'now': f'{now}'})\n","            wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","        # checkpoint and rollback\n","        # Note: this is a form of polution of the validation set\n","        if validation_loss < best_validation_loss:\n","            best_validation_loss = validation_loss\n","            patience_counter = 0\n","            t.save(model.state_dict(), f'weights/best_{now}_{validation_loss:.2f}.pt')\n","            t.save({\n","                'model': model.state_dict(),\n","                'opt': opt.state_dict(),\n","                'scheduler': scheduler.state_dict(),\n","            },  'best_checkpoint.pt')\n","        else: patience_counter += 1\n","        if wnb: wandb.log({'patience': patience_counter})\n","        if patience_counter > patience:\n","            print(f'rollback to checkpoint {now}')\n","            patience_counter = 0\n","            checkpoint = t.load('best_checkpoint.pt')\n","            model.load_state_dict(checkpoint['model'])\n","            opt.load_state_dict(checkpoint['opt'])\n","            scheduler.load_state_dict(checkpoint['scheduler'])\n","        \n","    if wnb: wandb.finish()\n","\n","# memory_train(model, opt, wnb=True, data_augmentation=True)"]},{"cell_type":"markdown","metadata":{},"source":["## staged"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:14:10.391136Z","iopub.status.busy":"2024-03-29T21:14:10.390404Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeluche\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240330_045624-5ovufe8f</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/5ovufe8f' target=\"_blank\">golden-planet-124</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/5ovufe8f' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/5ovufe8f</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e55b3b4c5202440f8bb5d22cc47b3244","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1856 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bae63f61eef84200ab8e248bc7f38f99","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76daa9dbdc864a01a93d5df2d1e5f809","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"701144bd19114c5da93840cfecebec18","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m replay_buffer\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m---> 47\u001b[0m \u001b[43mstaged_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwnb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[15], line 33\u001b[0m, in \u001b[0;36mstaged_train\u001b[0;34m(model, opt, mini_epochs, wnb, data_augmentation)\u001b[0m\n\u001b[1;32m     31\u001b[0m logs \u001b[38;5;241m=\u001b[39m model(x_train\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mKLDivLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m loss \u001b[38;5;241m=\u001b[39m kl_loss(logs, \u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     34\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def populate_buffer(buffer_size=300):\n","    while True:\n","        limited_replay_buffer = []\n","        tq = tqdm(train_dataloader)\n","        for x_train, y_train in tq:\n","            limited_replay_buffer.append((x_train, y_train))\n","            if len(limited_replay_buffer) >= buffer_size:\n","                yield limited_replay_buffer\n","                del limited_replay_buffer\n","                limited_replay_buffer = []\n","\n","def staged_train(model, opt, mini_epochs, wnb=True, data_augmentation=False):\n","    model.train()\n","    validation_test, validation_test_label = next(test_dataloader.__iter__())\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","\n","    # rb = [next(iter(train_dataloader))]\n","    # for _ in range(1000):\n","        # replay_buffer = rb\n","    for replay_buffer in populate_buffer():\n","        for epoch in tqdm(range(mini_epochs)):\n","            for x_train, y_train in replay_buffer:\n","                # TODO: use variable alpha based on mini_epoch\n","                if data_augmentation: x_train = augment_data(x_train, alpha=random.choice([0.01, 0.05, 0.1])) #, 0.15, 0.2, 0.3]))\n","                logs = model(x_train.to(device)).log_softmax(-1)\n","                kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","                loss = kl_loss(logs, y_train.to(device))\n","                opt.zero_grad()\n","                loss.backward()\n","                opt.step()\n","                if wnb: wandb.log({'loss': loss.item()})\n","        \n","            now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","            if wnb:\n","                wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","                wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","            t.save(model.state_dict(), f'weights/gru-4-splits_{now}.pt')\n","        del replay_buffer\n","    if wnb: wandb.finish()\n","\n","# staged_train(model, opt, mini_epochs=20, wnb=True, data_augmentation=True)"]},{"cell_type":"markdown","metadata":{},"source":["# validation"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>eeg_id</th>\n","      <th>eeg_sub_id</th>\n","      <th>eeg_label_offset_seconds</th>\n","      <th>spectrogram_id</th>\n","      <th>spectrogram_sub_id</th>\n","      <th>spectrogram_label_offset_seconds</th>\n","      <th>label_id</th>\n","      <th>patient_id</th>\n","      <th>expert_consensus</th>\n","      <th>seizure_vote</th>\n","      <th>lpd_vote</th>\n","      <th>gpd_vote</th>\n","      <th>lrda_vote</th>\n","      <th>grda_vote</th>\n","      <th>other_vote</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>203</th>\n","      <td>362880153</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>8412233</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>2100670995</td>\n","      <td>55611</td>\n","      <td>Other</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>204</th>\n","      <td>362880153</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>8412233</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>4054204384</td>\n","      <td>55611</td>\n","      <td>Other</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1891</th>\n","      <td>40748672</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>25489747</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>831645482</td>\n","      <td>53731</td>\n","      <td>LPD</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1892</th>\n","      <td>40748672</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>25489747</td>\n","      <td>1</td>\n","      <td>4.0</td>\n","      <td>2896698422</td>\n","      <td>53731</td>\n","      <td>LPD</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1893</th>\n","      <td>40748672</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>25489747</td>\n","      <td>2</td>\n","      <td>8.0</td>\n","      <td>4207805803</td>\n","      <td>53731</td>\n","      <td>LPD</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>105214</th>\n","      <td>2452371409</td>\n","      <td>43</td>\n","      <td>104.0</td>\n","      <td>2102491271</td>\n","      <td>43</td>\n","      <td>104.0</td>\n","      <td>210806234</td>\n","      <td>63023</td>\n","      <td>LRDA</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>105215</th>\n","      <td>2452371409</td>\n","      <td>44</td>\n","      <td>106.0</td>\n","      <td>2102491271</td>\n","      <td>44</td>\n","      <td>106.0</td>\n","      <td>110551487</td>\n","      <td>63023</td>\n","      <td>LRDA</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>105216</th>\n","      <td>2452371409</td>\n","      <td>45</td>\n","      <td>108.0</td>\n","      <td>2102491271</td>\n","      <td>45</td>\n","      <td>108.0</td>\n","      <td>3653683656</td>\n","      <td>63023</td>\n","      <td>LRDA</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>105489</th>\n","      <td>107362020</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>2111039330</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>318487679</td>\n","      <td>59230</td>\n","      <td>GPD</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>105490</th>\n","      <td>107362020</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>2111039330</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>1451599106</td>\n","      <td>59230</td>\n","      <td>GPD</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1374 rows × 15 columns</p>\n","</div>"],"text/plain":["            eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n","203      362880153           0                       0.0         8412233   \n","204      362880153           1                       4.0         8412233   \n","1891      40748672           0                       0.0        25489747   \n","1892      40748672           1                       4.0        25489747   \n","1893      40748672           2                       8.0        25489747   \n","...            ...         ...                       ...             ...   \n","105214  2452371409          43                     104.0      2102491271   \n","105215  2452371409          44                     106.0      2102491271   \n","105216  2452371409          45                     108.0      2102491271   \n","105489   107362020           0                       0.0      2111039330   \n","105490   107362020           1                       2.0      2111039330   \n","\n","        spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n","203                      0                               0.0  2100670995   \n","204                      1                               4.0  4054204384   \n","1891                     0                               0.0   831645482   \n","1892                     1                               4.0  2896698422   \n","1893                     2                               8.0  4207805803   \n","...                    ...                               ...         ...   \n","105214                  43                             104.0   210806234   \n","105215                  44                             106.0   110551487   \n","105216                  45                             108.0  3653683656   \n","105489                   0                               0.0   318487679   \n","105490                   1                               2.0  1451599106   \n","\n","        patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  \\\n","203          55611            Other             0         0         2   \n","204          55611            Other             0         0         2   \n","1891         53731              LPD             3        10         2   \n","1892         53731              LPD             3        10         2   \n","1893         53731              LPD             3        10         2   \n","...            ...              ...           ...       ...       ...   \n","105214       63023             LRDA             0         0         0   \n","105215       63023             LRDA             0         0         0   \n","105216       63023             LRDA             0         0         0   \n","105489       59230              GPD             0         0        12   \n","105490       59230              GPD             0         0        12   \n","\n","        lrda_vote  grda_vote  other_vote  \n","203             0          1          10  \n","204             0          1          10  \n","1891            0          0           0  \n","1892            0          0           0  \n","1893            0          0           0  \n","...           ...        ...         ...  \n","105214          8          2           1  \n","105215          8          2           1  \n","105216          8          2           1  \n","105489          0          0           2  \n","105490          0          0           2  \n","\n","[1374 rows x 15 columns]"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["df = train_df[train_df['spectrogram_id'].isin(test_ids)]\n","df[df[TARGETS].sum(axis=1) > 7]"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_3083955/143691869.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  return df.groupby(key).apply(lambda x: x.sample(1), include_groups=True).reset_index(drop=True)\n"]},{"name":"stdout","output_type":"stream","text":["fold=0 0.7797\n","fold=1 0.7888\n","fold=2 0.8444\n","fold=3 0.7345\n","fold=4 0.7508\n","fold=5 0.7975\n","fold=6 0.7703\n","mean-monster 0.7809\n"]}],"source":["def scope(folds=7):\n","    GC()\n","    train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","    train_df = remove_overlaps(train_df)\n","    test_indices = train_df[train_df['spectrogram_id'].isin(test_ids)].index.tolist()\n","\n","    # do it on the right side of the distribution instead\n","    # df = train_df[train_df['spectrogram_id'].isin(test_ids)]\n","    # test_indices = df[df[TARGETS].sum(axis=1) > 7].index.tolist()\n","\n","    test_dataset = Subset(dataset, test_indices)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","\n","    models = []\n","    for fold in range(folds):\n","        model = Model().to(device)\n","        model.load_state_dict(t.load(f'fold/best_{fold}.pt'))\n","        models.append(model)\n","        loss = full_validation(model, test_dataloader)\n","        print(f'{fold=} {loss.item():.4f}')\n","    loss = multi_model_full_validation(models, test_dataloader)\n","    print(f'mean-monster {loss.item():.4f}')\n","\n","scope()"]},{"cell_type":"markdown","metadata":{},"source":["# save / load"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# t.save(model.state_dict(),'model-weights4.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# model = SeparatedGRU().to(device)\n","# model.load_state_dict(t.load('weights/gru-4-splits_2024-03-24_15h03.pt', map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train(): train: 0.3067223824690105\n","\n","train(): test:  0.7667477726504927\n","\n","--\n","\n","eval(): train   0.38911351894595714\n","\n","eval(): test    0.7780192006451506\n"]}],"source":["x_train, y_train = next(train_dataloader.__iter__())\n","x_val, y_val = next(test_dataloader.__iter__())\n","\n","print(f'train(): train: {eval(model, x_train, y_train, do_eval=False)}')\n","print(f'train(): test:  {eval(model, x_val, y_val, do_eval=False)}')\n","print('--')\n","print(f'eval(): train   {eval(model, x_train, y_train, do_eval=True)}')\n","print(f'eval(): test    {eval(model, x_val, y_val, do_eval=True)}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# submit"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@t.no_grad()\n","def submit(model, test_dataloader, test_df):\n","    model.eval()\n","    res = []\n","    for batch in test_dataloader:\n","        prob = model(batch.to(device)).softmax(-1)\n","        res.append(prob.detach().cpu())\n","\n","    res = t.cat(res, dim=0)\n","    sub = test_df[[\"eeg_id\"]].copy()\n","    sub[TARGETS] = res\n","    sub.to_csv('submission.csv',index=False)\n","    print('Submission shape',sub.shape)\n","    display(sub.head())"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4638387,"sourceId":7898450,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
