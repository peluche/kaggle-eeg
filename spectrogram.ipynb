{"cells":[{"cell_type":"markdown","metadata":{},"source":["# imports"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-29T18:57:28.868967Z","iopub.status.busy":"2024-03-29T18:57:28.868609Z","iopub.status.idle":"2024-03-29T18:57:34.421266Z","shell.execute_reply":"2024-03-29T18:57:34.420178Z","shell.execute_reply.started":"2024-03-29T18:57:28.868938Z"},"trusted":true},"outputs":[],"source":["from datetime import datetime\n","import random\n","# import einops\n","import wandb\n","import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt \n","from torch.utils.data import Dataset, DataLoader, random_split, Subset\n","import torch\n","import torch as t\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from functools import lru_cache\n","\n","device = 'cuda' if t.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["# utils"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:03:56.118424Z","iopub.status.busy":"2024-03-29T21:03:56.118030Z","iopub.status.idle":"2024-03-29T21:03:56.123348Z","shell.execute_reply":"2024-03-29T21:03:56.122133Z","shell.execute_reply.started":"2024-03-29T21:03:56.118389Z"},"trusted":true},"outputs":[],"source":["import gc \n","def GC():\n","    gc.collect()\n","    t.cuda.empty_cache()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:13:57.721424Z","iopub.status.busy":"2024-03-29T21:13:57.721022Z","iopub.status.idle":"2024-03-29T21:13:57.729747Z","shell.execute_reply":"2024-03-29T21:13:57.728733Z","shell.execute_reply.started":"2024-03-29T21:13:57.721391Z"},"trusted":true},"outputs":[],"source":["# validation / inference loss\n","@t.no_grad()\n","def eval(model, x, y, do_eval=True):\n","    assert not x.isnan().any()\n","    assert not y.isnan().any()\n","    if do_eval: model.eval()\n","    else: model.train()\n","    logs = model(x.to(device)).log_softmax(-1)\n","    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","    loss = kl_loss(logs, y.to(device))\n","    model.train()\n","    return loss"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:14:00.780275Z","iopub.status.busy":"2024-03-29T21:14:00.779611Z","iopub.status.idle":"2024-03-29T21:14:00.787552Z","shell.execute_reply":"2024-03-29T21:14:00.786385Z","shell.execute_reply.started":"2024-03-29T21:14:00.780241Z"},"trusted":true},"outputs":[],"source":["@t.no_grad()\n","def augment_data(data, alpha=0.3):\n","    # was alpha=0.01 try 0.3\n","    # data → ('batch', 'seq', 'channel')\n","    data = data.to(device)\n","    std = data.std(dim=(2, 3), keepdim=True)\n","    noise = t.randn_like(data, device=device) * std * alpha\n","    return data + noise\n","\n","def augment_if(data, iter):\n","    if iter == 0: return data\n","    return augment_data(data)"]},{"cell_type":"markdown","metadata":{},"source":["# config"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:45:07.285132Z","iopub.status.busy":"2024-03-29T20:45:07.284215Z","iopub.status.idle":"2024-03-29T20:45:07.289183Z","shell.execute_reply":"2024-03-29T20:45:07.288167Z","shell.execute_reply.started":"2024-03-29T20:45:07.285098Z"},"trusted":true},"outputs":[],"source":["batch_size = 55\n","prefetch_factor = 10\n","num_workers = 3"]},{"cell_type":"markdown","metadata":{},"source":["# data"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T19:06:20.062887Z","iopub.status.busy":"2024-03-29T19:06:20.062259Z","iopub.status.idle":"2024-03-29T19:06:20.071931Z","shell.execute_reply":"2024-03-29T19:06:20.070945Z","shell.execute_reply.started":"2024-03-29T19:06:20.062855Z"},"trusted":true},"outputs":[],"source":["train_path = './hms-harmful-brain-activity-classification/train_spectrograms/'\n","train_spec_path = './hms-harmful-brain-activity-classification/train_spectrograms/'\n","BASE_PATH = './hms-harmful-brain-activity-classification/'\n","PRE_PROCESSED_PATH = './spectrograms/'\n","\n","FEATS_FOR_REAL = ['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2', 'EKG']\n","#                   0      1     2     3     4     5     6     7     8     9    10     11    12    13    14    15    16    17    18    19\n","# group by semantic groups LP, LL, RP, RR https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Jan-2024/montage.png\n","# GROUPS = [\n","#     ['Fp1', 'F3', 'C3', 'P3', 'O1'],\n","#     ['Fp1', 'F7', 'T3', 'T5', 'O1'],\n","#     ['Fp2', 'F4', 'C4', 'P4', 'O2'],\n","#     ['Fp2', 'F8', 'T4', 'T6', 'O2'],\n","# ]\n","GROUPS_IDS = [\n","    [0, 1, 2, 3, 7],\n","    [0, 4, 5, 6, 7],\n","    [11, 12, 13, 14, 18],\n","    [11, 15, 16, 17, 18],\n","    # [8, 9, 10, 19] # TODO: try with leftovers?\n","]\n","\n","GROUPS_IDS2 = [\n","    [0, 1, 2, 3, 7],\n","    [0, 4, 5, 6, 7],\n","    [11, 12, 13, 14, 18],\n","    [11, 15, 16, 17, 18],\n","    [8, 9, 10],\n","]\n","\n","\n","# LEFTOVERS = [8, 9, 10]\n","# EKG = [19]\n","# TODO: add frequency domain with fourier's transform\n","# TODO: add spectrogram to process with conv2d\n","# TODO: merge several models together\n","# TODO: when submitting round values close to 0 to exactly 0 and rebalance the rest to sum() == 1 for free boost\n","\n","TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote','other_vote']"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:03:47.810752Z","iopub.status.busy":"2024-03-29T20:03:47.809848Z","iopub.status.idle":"2024-03-29T20:03:47.979640Z","shell.execute_reply":"2024-03-29T20:03:47.978834Z","shell.execute_reply.started":"2024-03-29T20:03:47.810718Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(f'{BASE_PATH}/train.csv')\n","# test_df = pd.read_csv(f'{BASE_PATH}/test.csv')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T19:15:18.859764Z","iopub.status.busy":"2024-03-29T19:15:18.859118Z","iopub.status.idle":"2024-03-29T19:15:18.863858Z","shell.execute_reply":"2024-03-29T19:15:18.862925Z","shell.execute_reply.started":"2024-03-29T19:15:18.859730Z"},"trusted":true},"outputs":[],"source":["# columns = []"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:36:23.158813Z","iopub.status.busy":"2024-03-29T20:36:23.157986Z","iopub.status.idle":"2024-03-29T20:36:23.169504Z","shell.execute_reply":"2024-03-29T20:36:23.168569Z","shell.execute_reply.started":"2024-03-29T20:36:23.158779Z"},"trusted":true},"outputs":[],"source":["class Dataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","        self.dataframe = train_df\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx): # preprocessed version\n","        row = self.dataframe.iloc[idx]\n","        id = row['spectrogram_id']\n","        sub_id = row['spectrogram_sub_id']\n","        path = f'{PRE_PROCESSED_PATH}/{id}_{sub_id}.pt'\n","        data = t.load(path)\n","        labels = row[TARGETS].values.astype(np.float64)\n","        labels = labels / np.sum(labels)\n","        labels_out = t.tensor(labels, dtype=t.float64)\n","        return data, labels_out"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T19:32:52.947658Z","iopub.status.busy":"2024-03-29T19:32:52.946745Z","iopub.status.idle":"2024-03-29T19:32:52.955390Z","shell.execute_reply":"2024-03-29T19:32:52.954371Z","shell.execute_reply.started":"2024-03-29T19:32:52.947619Z"},"trusted":true},"outputs":[],"source":["# def plot_spectogram(spec_df, prefixes, title = \"Spectogram\"):\n","#     fig = sp.make_subplots(rows=len(prefixes), cols=1, subplot_titles=prefixes)\n","#     for i, prefix in enumerate(prefixes):\n","#         prefix_df = spec_df.filter(regex=f'^{prefix}', axis=1)\n","#         epsilon = 1e-10\n","#         fig.add_trace(go.Heatmap(z=np.log(prefix_df + epsilon).T,\n","#                                  y=pd.to_numeric(prefix_df.columns.str.replace(f\"{prefix}_\", '')),\n","#                                  coloraxis=\"coloraxis\"),\n","#                       row=i+1, col=1)\n","#          # Update x-axis and y-axis labels\n","#         fig.update_xaxes(title_text=\"Time(Seconds)\", row=i+1, col=1)\n","#         fig.update_yaxes(title_text=\"Frequency(Hz)\", row=i+1, col=1)\n","#         # update coloraxis\n","#         fig.update_layout(coloraxis = {'colorscale':'Jet'}, height=1500,title_text=title)\n","#     fig.show()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T20:45:11.990547Z","iopub.status.busy":"2024-03-29T20:45:11.989709Z","iopub.status.idle":"2024-03-29T20:45:12.016792Z","shell.execute_reply":"2024-03-29T20:45:12.015864Z","shell.execute_reply.started":"2024-03-29T20:45:11.990515Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(99743, 7057)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dataset = Dataset()\n","ids = train_df['spectrogram_id'].unique()\n","np.random.shuffle(ids)\n","split = int(len(ids) * 0.95)\n","\n","train_ids = ids[:split]\n","test_ids = ids[split:]\n","\n","now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","t.save(t.tensor(train_ids), f'./splits/{now}_train_ids.pt')\n","t.save(t.tensor(train_ids), f'./splits/{now}_test_ids.pt')\n","\n","train_indices = train_df[train_df['spectrogram_id'].isin(train_ids)].index.tolist()\n","test_indices = train_df[train_df['spectrogram_id'].isin(test_ids)].index.tolist()\n","\n","train_dataset = Subset(dataset, train_indices)\n","test_dataset = Subset(dataset, test_indices)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, prefetch_factor=prefetch_factor, shuffle=True)\n","\n","len(train_dataset), len(test_dataset)"]},{"cell_type":"markdown","metadata":{},"source":["# model 👯‍♀️"]},{"cell_type":"markdown","metadata":{},"source":["## conv1d + GRU"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["3456"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["128 * 9 * 3"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:02:35.320633Z","iopub.status.busy":"2024-03-29T21:02:35.320217Z","iopub.status.idle":"2024-03-29T21:02:40.982361Z","shell.execute_reply":"2024-03-29T21:02:40.981275Z","shell.execute_reply.started":"2024-03-29T21:02:35.320600Z"},"trusted":true},"outputs":[],"source":["class CNNBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, dropout, stride=1):\n","        super(CNNBlock, self).__init__()\n","        downsample = in_channels != out_channels\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding='same', padding_mode='reflect'),\n","            # nn.BatchNorm2d(out_channels), # TODO: I hate batchnorm -_-\n","            nn.LeakyReLU(),\n","            nn.Dropout(dropout),\n","            *(nn.MaxPool2d(kernel_size=2, stride=2),) if downsample else ()\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","        \n","class Model(nn.Module):\n","    def __init__(self, convs=[4, 8, 8, 8, 16, 16, 16, 32, 32, 32, 64, 64, 64, 128, 129], hidden=256, dropout=0.2):\n","        super().__init__()\n","\n","        self.cnn = nn.Sequential(\n","            *[CNNBlock(in_chan, out_chan, dropout=dropout) for in_chan, out_chan in zip(convs, convs[1:])]\n","        )\n","        self.head = nn.Sequential(\n","            nn.Flatten(start_dim=1, end_dim=-1),\n","            nn.Linear(129 * 4, hidden),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden, 6),\n","        )\n","\n","    def forward(self, x):\n","        x = self.cnn(x)\n","        x = self.head(x)\n","        return x\n","\n","def test():\n","    m = Model().to(device)\n","    x, y = next(train_dataloader.__iter__())\n","    print(f'{x.shape=}')\n","    r = m(x.to(device))\n","    print(f'{r.shape=}')\n","    \n","# test()"]},{"cell_type":"markdown","metadata":{},"source":["# train"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:04:08.985271Z","iopub.status.busy":"2024-03-29T21:04:08.984919Z","iopub.status.idle":"2024-03-29T21:04:11.427419Z","shell.execute_reply":"2024-03-29T21:04:11.426486Z","shell.execute_reply.started":"2024-03-29T21:04:08.985245Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model has 479247 params\n"]}],"source":["GC()\n","model = Model().to(device)\n","opt = t.optim.Adam(model.parameters(), lr=3e-4, weight_decay=3e-5)\n","print(f'model has {sum(p.numel() for p in model.parameters())} params')"]},{"cell_type":"markdown","metadata":{},"source":["## staged"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T21:14:10.391136Z","iopub.status.busy":"2024-03-29T21:14:10.390404Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeluche\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.16.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.4"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/mnt/d/kaggle/wandb/run-20240330_031613-usqwfgmi</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/usqwfgmi' target=\"_blank\">upbeat-donkey-120</a></strong> to <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/peluche/kaggle-eeg-rc' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/peluche/kaggle-eeg-rc/runs/usqwfgmi' target=\"_blank\">https://wandb.ai/peluche/kaggle-eeg-rc/runs/usqwfgmi</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba8f6942bcff46a586358491c016a6bd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1814 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a73be85b7b7b41c7b5cfdf48cd0fdecb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"822e70d835f9405589913e477b2195dc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2456d8ba23a14b8e8b7a329bea01a0a2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6bdc22bdb01940cebeb582585af733dd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f495aa18b04546f791be4caa86b1bb56","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25fd06d9907b48fe979befe1ebf880d6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab66d160e4dd4a0aacd1c6214d924c03","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1814 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76403abf87a749e5ad58454c8432dffe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e9be5d56d2e74fddb75c0aac0e0e406c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"918c72dfa4854746926bbb1f9cd68e65","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d241cd9b9cc7466e9c53d04db5aabd2a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a916c34774004d4bb200e7c6271bd751","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ceb3bb5cbad4b26abe599d01d98a600","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f285c4a187904ee19ee50285576303a6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1814 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"779e70f8d82c4d4f95049b18d9c48f1e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m replay_buffer\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m---> 47\u001b[0m \u001b[43mstaged_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmini_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwnb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[15], line 35\u001b[0m, in \u001b[0;36mstaged_train\u001b[0;34m(model, opt, mini_epochs, wnb, data_augmentation)\u001b[0m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m kl_loss(logs, y_train\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     34\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 35\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wnb: wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem()})\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def populate_buffer(buffer_size=300):\n","    while True:\n","        limited_replay_buffer = []\n","        tq = tqdm(train_dataloader)\n","        for x_train, y_train in tq:\n","            limited_replay_buffer.append((x_train, y_train))\n","            if len(limited_replay_buffer) >= buffer_size:\n","                yield limited_replay_buffer\n","                del limited_replay_buffer\n","                limited_replay_buffer = []\n","\n","def staged_train(model, opt, mini_epochs, wnb=True, data_augmentation=False):\n","    model.train()\n","    validation_test, validation_test_label = next(test_dataloader.__iter__())\n","    validation_train, validation_train_label = next(train_dataloader.__iter__())\n","\n","    if wnb:\n","        wandb.init(project='kaggle-eeg-rc')\n","        now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","        wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","        wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","\n","    # rb = [next(iter(train_dataloader))]\n","    # for _ in range(1000):\n","        # replay_buffer = rb\n","    for replay_buffer in populate_buffer():\n","        for epoch in tqdm(range(mini_epochs)):\n","            for x_train, y_train in replay_buffer:\n","                # TODO: use variable alpha based on mini_epoch\n","                if data_augmentation: x_train = augment_data(x_train, alpha=random.choice([0.01, 0.05, 0.1])) #, 0.15, 0.2, 0.3]))\n","                logs = model(x_train.to(device)).log_softmax(-1)\n","                kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n","                loss = kl_loss(logs, y_train.to(device))\n","                opt.zero_grad()\n","                loss.backward()\n","                opt.step()\n","                if wnb: wandb.log({'loss': loss.item()})\n","        \n","            now = datetime.now().strftime(\"%Y-%m-%d_%Hh%M\")\n","            if wnb:\n","                wandb.log({'val_test':   eval(model, validation_test, validation_test_label, do_eval=True), 'now': f'{now}'})\n","                wandb.log({'val_train':  eval(model, validation_train, validation_train_label, do_eval=True), 'now': f'{now}'})\n","            t.save(model.state_dict(), f'weights/gru-4-splits_{now}.pt')\n","        del replay_buffer\n","    if wnb: wandb.finish()\n","\n","staged_train(model, opt, mini_epochs=20, wnb=True, data_augmentation=True)"]},{"cell_type":"markdown","metadata":{},"source":["# save / load"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# t.save(model.state_dict(),'model-weights4.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# model = SeparatedGRU().to(device)\n","# model.load_state_dict(t.load('weights/gru-4-splits_2024-03-24_15h03.pt', map_location=device))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["train(): train: 0.3067223824690105\n","\n","train(): test:  0.7667477726504927\n","\n","--\n","\n","eval(): train   0.38911351894595714\n","\n","eval(): test    0.7780192006451506\n"]}],"source":["x_train, y_train = next(train_dataloader.__iter__())\n","x_val, y_val = next(test_dataloader.__iter__())\n","\n","print(f'train(): train: {eval(model, x_train, y_train, do_eval=False)}')\n","print(f'train(): test:  {eval(model, x_val, y_val, do_eval=False)}')\n","print('--')\n","print(f'eval(): train   {eval(model, x_train, y_train, do_eval=True)}')\n","print(f'eval(): test    {eval(model, x_val, y_val, do_eval=True)}')\n"]},{"cell_type":"markdown","metadata":{},"source":["# submit"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@t.no_grad()\n","def submit(model, test_dataloader, test_df):\n","    model.eval()\n","    res = []\n","    for batch in test_dataloader:\n","        prob = model(batch.to(device)).softmax(-1)\n","        res.append(prob.detach().cpu())\n","\n","    res = t.cat(res, dim=0)\n","    sub = test_df[[\"eeg_id\"]].copy()\n","    sub[TARGETS] = res\n","    sub.to_csv('submission.csv',index=False)\n","    print('Submission shape',sub.shape)\n","    display(sub.head())"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7469972,"sourceId":59093,"sourceType":"competition"},{"datasetId":4638387,"sourceId":7898450,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
